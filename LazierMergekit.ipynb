{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jankovicsandras/ml/blob/main/LazierMergekit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü•±üò¥ LazierMergekit\n",
        "\n",
        "> üó£Ô∏è [Large Language Model Course](https://github.com/mlabonne/llm-course)\n",
        "\n",
        "‚ù§Ô∏è Created by [@maximelabonne](https://twitter.com/maximelabonne).\n",
        "\n",
        "This notebook allows you to easily merge multiple models using [mergekit](https://github.com/cg123/mergekit). To evaluate your merges, see [üßê LLM AutoEval](https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa?usp=sharing#scrollTo=elyxjYI_rY5W).\n",
        "\n",
        "Added [Llama.cpp](https://github.com/ggerganov/llama.cpp) quantization.\n",
        "\n",
        "*Special thanks to [@cg123](https://github.com/cg123) for this library and [@mrfakename](https://gist.github.com/fakerybakery) who told me about sharding (see his [Gist](https://gist.github.com/fakerybakery/d30a4d31b4f914757c1381166b9c683b)).*"
      ],
      "metadata": {
        "id": "1Wq4SB9A_9ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"Mindentural-7B-240124\"\n",
        "yaml_config = \"\"\"\n",
        "slices:\n",
        "  - sources:\n",
        "      - model: OpenPipe/mistral-ft-optimized-1218\n",
        "        layer_range: [0, 32]\n",
        "      - model: HyperbeeAI/Tulpar-7b-v2\n",
        "        layer_range: [0, 32]\n",
        "merge_method: slerp\n",
        "base_model: OpenPipe/mistral-ft-optimized-1218\n",
        "parameters:\n",
        "  t:\n",
        "    - filter: self_attn\n",
        "      value: [0, 0.5, 0.3, 0.7, 1]\n",
        "    - filter: mlp\n",
        "      value: [1, 0.5, 0.7, 0.3, 0]\n",
        "    - value: 0.5\n",
        "dtype: bfloat16\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LGd7jlfCpNcg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Run merge\n",
        "\n",
        "# @markdown ### Runtime type\n",
        "# @markdown Select your runtime (CPU, High RAM, GPU)\n",
        "\n",
        "runtime = \"CPU\" # @param [\"CPU\", \"CPU + High-RAM\", \"GPU\"]\n",
        "\n",
        "# @markdown ### Mergekit arguments\n",
        "# @markdown Use the `main` branch by default, [`mixtral`](https://github.com/cg123/mergekit/blob/mixtral/moe.md) if you want to create a Mixture of Experts.\n",
        "\n",
        "branch = \"main\" # @param [\"main\", \"mixtral\"]\n",
        "trust_remote_code = False # @param {type:\"boolean\"}\n",
        "\n",
        "# Install mergekit\n",
        "if branch == \"main\":\n",
        "    !git clone https://github.com/cg123/mergekit.git\n",
        "    !cd mergekit && pip install -qqq -e . --progress-bar off\n",
        "elif branch == \"mixtral\":\n",
        "    !git clone -b mixtral https://github.com/cg123/mergekit.git\n",
        "    !cd mergekit && pip install -qqq -e . --progress-bar off\n",
        "    !pip install -qqq -U transformers --progress-bar off\n",
        "\n",
        "# Save config as yaml file\n",
        "with open('config.yaml', 'w', encoding=\"utf-8\") as f:\n",
        "    f.write(yaml_config)\n",
        "\n",
        "# Base CLI\n",
        "if branch == \"main\":\n",
        "    cli = \"mergekit-yaml config.yaml merge --copy-tokenizer\"\n",
        "elif branch == \"mixtral\":\n",
        "    cli = \"mergekit-moe config.yaml merge --copy-tokenizer\"\n",
        "\n",
        "# Additional arguments\n",
        "if runtime == \"CPU\":\n",
        "    cli += \" --allow-crimes --out-shard-size 1B --lazy-unpickle\"\n",
        "elif runtime == \"GPU\":\n",
        "    cli += \" --cuda --low-cpu-memory\"\n",
        "if trust_remote_code:\n",
        "    cli += \" --trust-remote-code\"\n",
        "\n",
        "print(cli)\n",
        "\n",
        "# Merge models\n",
        "!{cli}"
      ],
      "metadata": {
        "id": "d5mYzDo1q96y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e4681e-993c-4356-d93c-9f2d0453a7f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mergekit' already exists and is not an empty directory.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for mergekit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "mergekit-yaml config.yaml merge --copy-tokenizer --allow-crimes --out-shard-size 1B --lazy-unpickle\n",
            "Warmup loader cache:   0% 0/2 [00:00<?, ?it/s]\n",
            "Fetching 8 files: 100% 8/8 [00:00<00:00, 9675.44it/s]\n",
            "Warmup loader cache:  50% 1/2 [00:00<00:00,  6.21it/s]\n",
            "Fetching 8 files: 100% 8/8 [00:00<00:00, 41070.30it/s]\n",
            "Warmup loader cache: 100% 2/2 [00:00<00:00,  6.33it/s]\n",
            "100% 1457/1457 [09:01<00:00,  2.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /root/.cache/huggingface/hub # IMPORTANT! Deleting the cached source models to free up space\n",
        "!ls -la\n",
        "!ls -la merge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c10c04-aea5-418c-a26b-8889673dce5d",
        "id": "YRwWx8ugnFjj"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 36\n",
            "drwxr-xr-x  1 root root 4096 Jan 24 13:09 .\n",
            "drwxr-xr-x  1 root root 4096 Jan 24 12:15 ..\n",
            "drwxr-xr-x  1 root root 4096 Jan 19 14:19 .config\n",
            "-rw-r--r--  1 root root  398 Jan 24 12:29 config.yaml\n",
            "drwxr-xr-x 21 root root 4096 Jan 24 12:48 llama.cpp\n",
            "drwxr-xr-x  2 root root 4096 Jan 24 12:38 merge\n",
            "drwxr-xr-x  1 root root 4096 Jan 19 14:20 sample_data\n",
            "total 14146392\n",
            "drwxr-xr-x 2 root root       4096 Jan 24 12:38 .\n",
            "drwxr-xr-x 1 root root       4096 Jan 24 13:09 ..\n",
            "-rw-r--r-- 1 root root        651 Jan 24 12:38 config.json\n",
            "-rw-r--r-- 1 root root        398 Jan 24 12:38 mergekit_config.yml\n",
            "-rw-r--r-- 1 root root 1912681584 Jan 24 12:30 model-00001-of-00008.safetensors\n",
            "-rw-r--r-- 1 root root 1979781456 Jan 24 12:31 model-00002-of-00008.safetensors\n",
            "-rw-r--r-- 1 root root 1946243968 Jan 24 12:33 model-00003-of-00008.safetensors\n",
            "-rw-r--r-- 1 root root 1979781416 Jan 24 12:34 model-00004-of-00008.safetensors\n",
            "-rw-r--r-- 1 root root 1862349080 Jan 24 12:35 model-00005-of-00008.safetensors\n",
            "-rw-r--r-- 1 root root 1916866512 Jan 24 12:36 model-00006-of-00008.safetensors\n",
            "-rw-r--r-- 1 root root 1979781456 Jan 24 12:38 model-00007-of-00008.safetensors\n",
            "-rw-r--r-- 1 root root  906012472 Jan 24 12:38 model-00008-of-00008.safetensors\n",
            "-rw-r--r-- 1 root root      22769 Jan 24 12:38 model.safetensors.index.json\n",
            "-rw-r--r-- 1 root root       1054 Jan 24 12:38 README.md\n",
            "-rw-r--r-- 1 root root        414 Jan 24 12:38 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root        916 Jan 24 12:38 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    1795303 Jan 24 12:38 tokenizer.json\n",
            "-rw-r--r-- 1 root root     493443 Jan 24 12:38 tokenizer.model\n",
            "14G\tmerge\n",
            "2.3M\t/opt/nvidia/nsight-compute/2023.2.2/extras/samples/uncoalescedGlobalAccesses\n",
            "124K\t/opt/nvidia/nsight-compute/2023.2.2/host/target-linux-x64/GpuMetrics\n",
            "1.5M\t/opt/nvidia/nsight-compute/2023.2.2/docs/ProfilingGuide/graphics\n",
            "1.9M\t/opt/nvidia/nsight-compute/2023.2.2/docs/ProfilingGuide\n",
            "308K\t/opt/nvidia/nsight-compute/2023.2.2/docs/CustomizationGuide/graphics\n",
            "408K\t/opt/nvidia/nsight-compute/2023.2.2/docs/CustomizationGuide\n",
            "1.5G\t/opt/nvidia/nsight-compute/2023.2.2\n",
            "1.5G\t/opt/nvidia/nsight-compute\n",
            "1.5G\t/opt/nvidia\n",
            "1.5G\t/opt\n",
            "1.1G\t/root/.cache/pip/http/3\n",
            "2.5G\t/root/.cache/pip/http\n",
            "2.5G\t/root/.cache/pip\n",
            "2.5G\t/root/.cache\n",
            "2.5G\t/root\n",
            "0\t/sys/bus/mdio_bus/drivers/Generic PHY\n",
            "0\t/sys/bus/mdio_bus/drivers/Generic Clause 45 PHY\n",
            "du: cannot read directory '/proc/62/task/62/net': Invalid argument\n",
            "du: cannot read directory '/proc/62/net': Invalid argument\n",
            "du: cannot access '/proc/15026/task/15026/fd/4': No such file or directory\n",
            "du: cannot access '/proc/15026/task/15026/fdinfo/4': No such file or directory\n",
            "du: cannot access '/proc/15026/fd/3': No such file or directory\n",
            "du: cannot access '/proc/15026/fdinfo/3': No such file or directory\n",
            "1.3G\t/usr/local/lib/python3.10/dist-packages/torch/lib\n",
            "1.4G\t/usr/local/lib/python3.10/dist-packages/torch\n",
            "1.2G\t/usr/local/lib/python3.10/dist-packages/nvidia/cudnn/lib\n",
            "1.2G\t/usr/local/lib/python3.10/dist-packages/nvidia/cudnn\n",
            "2.8G\t/usr/local/lib/python3.10/dist-packages/nvidia\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/third_party/eigen/Eigen/src/Core/arch/GPU\n",
            "184K\t/usr/local/lib/python3.10/dist-packages/notebook/i18n/fr_FR/LC_MESSAGES\n",
            "212K\t/usr/local/lib/python3.10/dist-packages/notebook/i18n/ja_JP/LC_MESSAGES\n",
            "180K\t/usr/local/lib/python3.10/dist-packages/notebook/i18n/zh_CN/LC_MESSAGES\n",
            "188K\t/usr/local/lib/python3.10/dist-packages/notebook/i18n/nl/LC_MESSAGES\n",
            "236K\t/usr/local/lib/python3.10/dist-packages/notebook/i18n/ru_RU/LC_MESSAGES\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/IMG/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/IMG\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/ARM/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/ARM\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/INTEL/__pycache__\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/INTEL\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/FJ/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/FJ\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/DFX/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/DFX\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/ANGLE/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/ANGLE\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/INGR/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/INGR\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/NVX/__pycache__\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/NVX\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/PGI/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/PGI\n",
            "88K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/APPLE/__pycache__\n",
            "172K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/APPLE\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/VIV/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/VIV\n",
            "528K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/EXT/__pycache__\n",
            "1.1M\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/EXT\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SGI/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SGI\n",
            "76K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/ATI/__pycache__\n",
            "148K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/ATI\n",
            "160K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SGIX/__pycache__\n",
            "320K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SGIX\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SUN/__pycache__\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SUN\n",
            "156K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/AMD/__pycache__\n",
            "308K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/AMD\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/OES/__pycache__\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/OES\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/HP/__pycache__\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/HP\n",
            "112K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/VERSION/__pycache__\n",
            "256K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/VERSION\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/IBM/__pycache__\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/IBM\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/QCOM/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/QCOM\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SGIS/__pycache__\n",
            "136K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SGIS\n",
            "584K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/NV/__pycache__\n",
            "1.2M\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/NV\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/S3/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/S3\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/__pycache__\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/REND/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/REND\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SUNX/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/SUNX\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/DMP/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/DMP\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/MESA/__pycache__\n",
            "80K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/MESA\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/GREMEDY/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/GREMEDY\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/OML/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/OML\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/MESAX/__pycache__\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/MESAX\n",
            "808K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/ARB/__pycache__\n",
            "1.7M\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/ARB\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/OVR/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/OVR\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/KHR/__pycache__\n",
            "140K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/KHR\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/WIN/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL/WIN\n",
            "6.4M\t/usr/local/lib/python3.10/dist-packages/OpenGL/GL\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/OpenGL/platform/__pycache__\n",
            "120K\t/usr/local/lib/python3.10/dist-packages/OpenGL/platform\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/Tk/__pycache__\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/OpenGL/Tk\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/osmesa/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/osmesa\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/IMG/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/IMG\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/ARM/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/ARM\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/HI/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/HI\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/ANGLE/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/ANGLE\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/NOK/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/NOK\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/TIZEN/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/TIZEN\n",
            "92K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/EXT/__pycache__\n",
            "184K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/EXT\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/VERSION/__pycache__\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/VERSION\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/ANDROID/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/ANDROID\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/NV/__pycache__\n",
            "128K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/NV\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/__pycache__\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/MESA/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/MESA\n",
            "152K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/KHR/__pycache__\n",
            "304K\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL/KHR\n",
            "1.1M\t/usr/local/lib/python3.10/dist-packages/OpenGL/EGL\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/IMG/__pycache__\n",
            "88K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/IMG\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/ARM/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/ARM\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/INTEL/__pycache__\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/INTEL\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/FJ/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/FJ\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/ANGLE/__pycache__\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/ANGLE\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/NVX/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/NVX\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/APPLE/__pycache__\n",
            "88K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/APPLE\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/VIV/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/VIV\n",
            "420K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/EXT/__pycache__\n",
            "840K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/EXT\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/AMD/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/AMD\n",
            "220K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/OES/__pycache__\n",
            "444K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/OES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/VERSION/__pycache__\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/VERSION\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/ANDROID/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/ANDROID\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/QCOM/__pycache__\n",
            "136K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/QCOM\n",
            "292K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/NV/__pycache__\n",
            "584K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/NV\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/__pycache__\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/ES/__pycache__\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/ES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/DMP/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/DMP\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/MESA/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/MESA\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/OVR/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/OVR\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/KHR/__pycache__\n",
            "144K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2/KHR\n",
            "2.9M\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES2\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES3/VERSION/__pycache__\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES3/VERSION\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES3/__pycache__\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES3\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/INTEL/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/INTEL\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/DFX/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/DFX\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/EXT/__pycache__\n",
            "136K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/EXT\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/SGI/__pycache__\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/SGI\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/SGIX/__pycache__\n",
            "88K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/SGIX\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/SUN/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/SUN\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/AMD/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/AMD\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/VERSION/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/VERSION\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/SGIS/__pycache__\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/SGIS\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/NV/__pycache__\n",
            "120K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/NV\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/__pycache__\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/MESA/__pycache__\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/MESA\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/OML/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/OML\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/ARB/__pycache__\n",
            "116K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX/ARB\n",
            "828K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLX\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/IMG/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/IMG\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/ARM/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/ARM\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/INTEL/__pycache__\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/INTEL\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/FJ/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/FJ\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/DFX/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/DFX\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/ANGLE/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/ANGLE\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/INGR/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/INGR\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/NVX/__pycache__\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/NVX\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/PGI/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/PGI\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/APPLE/__pycache__\n",
            "144K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/APPLE\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/VIV/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/VIV\n",
            "564K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/EXT/__pycache__\n",
            "1.1M\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/EXT\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SGI/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SGI\n",
            "80K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/ATI/__pycache__\n",
            "160K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/ATI\n",
            "164K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SGIX/__pycache__\n",
            "324K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SGIX\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SUN/__pycache__\n",
            "76K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SUN\n",
            "156K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/AMD/__pycache__\n",
            "312K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/AMD\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/OES/__pycache__\n",
            "84K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/OES\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/HP/__pycache__\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/HP\n",
            "296K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/VERSION/__pycache__\n",
            "552K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/VERSION\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/IBM/__pycache__\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/IBM\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/QCOM/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/QCOM\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SGIS/__pycache__\n",
            "136K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SGIS\n",
            "556K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/NV/__pycache__\n",
            "1.1M\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/NV\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/S3/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/S3\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/__pycache__\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/REND/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/REND\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SUNX/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/SUNX\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/DMP/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/DMP\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/MESA/__pycache__\n",
            "80K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/MESA\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/GREMEDY/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/GREMEDY\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/OML/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/OML\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/MESAX/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/MESAX\n",
            "796K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/ARB/__pycache__\n",
            "1.6M\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/ARB\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/OVR/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/OVR\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/KHR/__pycache__\n",
            "124K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/KHR\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/WIN/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL/WIN\n",
            "6.6M\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GL\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/osmesa/__pycache__\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/osmesa\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/IMG/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/IMG\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/ARM/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/ARM\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/HI/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/HI\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/ANGLE/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/ANGLE\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/NOK/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/NOK\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/TIZEN/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/TIZEN\n",
            "92K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/EXT/__pycache__\n",
            "184K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/EXT\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/VERSION/__pycache__\n",
            "80K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/VERSION\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/ANDROID/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/ANDROID\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/NV/__pycache__\n",
            "128K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/NV\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/__pycache__\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/MESA/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/MESA\n",
            "152K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/KHR/__pycache__\n",
            "304K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL/KHR\n",
            "1.1M\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/EGL\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/IMG/__pycache__\n",
            "88K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/IMG\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/ARM/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/ARM\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/INTEL/__pycache__\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/INTEL\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/FJ/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/FJ\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/ANGLE/__pycache__\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/ANGLE\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/NVX/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/NVX\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/APPLE/__pycache__\n",
            "88K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/APPLE\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/VIV/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/VIV\n",
            "428K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/EXT/__pycache__\n",
            "848K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/EXT\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/AMD/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/AMD\n",
            "216K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/OES/__pycache__\n",
            "440K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/OES\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/VERSION/__pycache__\n",
            "88K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/VERSION\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/ANDROID/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/ANDROID\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/QCOM/__pycache__\n",
            "128K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/QCOM\n",
            "284K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/NV/__pycache__\n",
            "572K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/NV\n",
            "52K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/__pycache__\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/ES/__pycache__\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/ES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/DMP/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/DMP\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/MESA/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/MESA\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/OVR/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/OVR\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/KHR/__pycache__\n",
            "124K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2/KHR\n",
            "3.1M\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES2\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES3/VERSION/__pycache__\n",
            "132K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES3/VERSION\n",
            "52K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES3/__pycache__\n",
            "344K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES3\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/INTEL/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/INTEL\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/DFX/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/DFX\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/EXT/__pycache__\n",
            "136K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/EXT\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/SGI/__pycache__\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/SGI\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/SGIX/__pycache__\n",
            "88K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/SGIX\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/SUN/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/SUN\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/AMD/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/AMD\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/VERSION/__pycache__\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/VERSION\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/SGIS/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/SGIS\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/NV/__pycache__\n",
            "112K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/NV\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/__pycache__\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/MESA/__pycache__\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/MESA\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/OML/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/OML\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/ARB/__pycache__\n",
            "112K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX/ARB\n",
            "848K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLX\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/__pycache__\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLUT/__pycache__\n",
            "100K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLUT\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/IMG/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/IMG\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/ARM/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/ARM\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/APPLE/__pycache__\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/APPLE\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/EXT/__pycache__\n",
            "128K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/EXT\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/AMD/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/AMD\n",
            "176K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/OES/__pycache__\n",
            "348K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/OES\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/VERSION/__pycache__\n",
            "84K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/VERSION\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/QCOM/__pycache__\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/QCOM\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/NV/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/NV\n",
            "52K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/__pycache__\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/KHR/__pycache__\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1/KHR\n",
            "1.1M\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLES1\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/DFX/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/DFX\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/EXT/__pycache__\n",
            "128K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/EXT\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/ATI/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/ATI\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/AMD/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/AMD\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/I3D/__pycache__\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/I3D\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/VERSION/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/VERSION\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/NV/__pycache__\n",
            "136K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/NV\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/__pycache__\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/OML/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/OML\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/ARB/__pycache__\n",
            "144K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/ARB\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/DL/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL/DL\n",
            "680K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/WGL\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLU/__pycache__\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLU\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLE/__pycache__\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw/GLE\n",
            "14M\t/usr/local/lib/python3.10/dist-packages/OpenGL/raw\n",
            "124K\t/usr/local/lib/python3.10/dist-packages/OpenGL/arrays/__pycache__\n",
            "260K\t/usr/local/lib/python3.10/dist-packages/OpenGL/arrays\n",
            "148K\t/usr/local/lib/python3.10/dist-packages/OpenGL/__pycache__\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/AGL/__pycache__\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/AGL\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLUT/__pycache__\n",
            "80K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLUT\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/IMG/__pycache__\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/IMG\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/ARM/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/ARM\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/APPLE/__pycache__\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/APPLE\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/EXT/__pycache__\n",
            "128K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/EXT\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/AMD/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/AMD\n",
            "172K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/OES/__pycache__\n",
            "344K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/OES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/VERSION/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/VERSION\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/QCOM/__pycache__\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/QCOM\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/NV/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/NV\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/__pycache__\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/KHR/__pycache__\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1/KHR\n",
            "832K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLES1\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/DFX/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/DFX\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/EXT/__pycache__\n",
            "128K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/EXT\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/ATI/__pycache__\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/ATI\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/AMD/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/AMD\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/I3D/__pycache__\n",
            "64K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/I3D\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/VERSION/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/VERSION\n",
            "76K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/NV/__pycache__\n",
            "152K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/NV\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/__pycache__\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/OML/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/OML\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/ARB/__pycache__\n",
            "144K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/ARB\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/DL/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL/DL\n",
            "656K\t/usr/local/lib/python3.10/dist-packages/OpenGL/WGL\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLU/EXT/__pycache__\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLU/EXT\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLU/__pycache__\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLU\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLE/__pycache__\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/OpenGL/GLE\n",
            "28M\t/usr/local/lib/python3.10/dist-packages/OpenGL\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/tornado/test/gettext_translations/fr_FR/LC_MESSAGES\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/cmake/data/share/cmake-3.27/Modules/UseSWIG\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/jupyter_server/i18n/zh_CN/LC_MESSAGES\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/sv/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/si/LC_MESSAGES\n",
            "140K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/et/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ta/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/zh_TW.Big5/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/fi/LC_MESSAGES\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ro/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/sr@latin/LC_MESSAGES\n",
            "232K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/el/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ur/LC_MESSAGES\n",
            "136K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/pl/LC_MESSAGES\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/bn/LC_MESSAGES\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/it/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/is/LC_MESSAGES\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/nb_NO/LC_MESSAGES\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/hu/LC_MESSAGES\n",
            "220K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/fr/LC_MESSAGES\n",
            "252K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/fa/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/hi_IN/LC_MESSAGES\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ar/LC_MESSAGES\n",
            "212K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/pt_BR/LC_MESSAGES\n",
            "112K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/sr/LC_MESSAGES\n",
            "120K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/hr/LC_MESSAGES\n",
            "200K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/es/LC_MESSAGES\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/uk_UA/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/cak/LC_MESSAGES\n",
            "112K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ne/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/zh_HK/LC_MESSAGES\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/lv/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/en_HK/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/bg/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/fr_FR/LC_MESSAGES\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/he/LC_MESSAGES\n",
            "112K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/da/LC_MESSAGES\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ca/LC_MESSAGES\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/de/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/mk/LC_MESSAGES\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/cs/LC_MESSAGES\n",
            "192K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/sk/LC_MESSAGES\n",
            "128K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ru/LC_MESSAGES\n",
            "220K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ko/LC_MESSAGES\n",
            "156K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/zh_TW/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/eo/LC_MESSAGES\n",
            "184K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/zh_CN/LC_MESSAGES\n",
            "180K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/tr/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/te/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/yue/LC_MESSAGES\n",
            "116K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/en_GB/LC_MESSAGES\n",
            "120K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/en_GB\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/pt_PT/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/sr_RS/LC_MESSAGES\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/cy/LC_MESSAGES\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/eu/LC_MESSAGES\n",
            "212K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/sq/LC_MESSAGES\n",
            "120K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/nl/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/pt/LC_MESSAGES\n",
            "224K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ja/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/ru_RU/LC_MESSAGES\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/vi/LC_MESSAGES\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/en_FR/LC_MESSAGES\n",
            "260K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/hi/LC_MESSAGES\n",
            "176K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/id/LC_MESSAGES\n",
            "100K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/sl/LC_MESSAGES\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/sphinx/locale/lt/LC_MESSAGES\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/GDAL-3.4.3.dist-info\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/sv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/si/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/et/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/ta/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/fi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/ro/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/sr@latin/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/el/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/ur/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/pl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/bn/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/it/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/nb_NO/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/hu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/fr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/fa/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/hi_IN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/ar/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/pt_BR/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/sr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/hr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/es/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/uk_UA/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/cak/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/ne/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/lv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/bg/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/he/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/da/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/ca/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/de/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/mk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/cs/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/sk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/ru/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/ko/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/zh_TW/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/eo/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/zh_CN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/tr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/te/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/pt_PT/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/sr_RS/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/cy/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/eu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/sq/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/nl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/pt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/ja/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/vi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/hi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/id/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/sl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/htmlhelp/locales/lt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/sv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/si/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/et/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/ta/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/fi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/ro/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/sr@latin/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/el/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/ur/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/pl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/bn/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/it/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/nb_NO/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/hu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/fr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/fa/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/hi_IN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/ar/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/pt_BR/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/sr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/hr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/es/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/uk_UA/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/cak/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/ne/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/lv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/bg/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/he/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/da/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/ca/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/de/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/mk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/cs/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/sk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/ru/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/ko/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/zh_TW/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/eo/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/zh_CN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/tr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/te/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/pt_PT/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/sr_RS/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/cy/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/eu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/sq/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/nl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/pt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/ja/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/vi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/hi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/id/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/sl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/serializinghtml/locales/lt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/sv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/si/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/et/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/ta/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/fi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/ro/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/sr@latin/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/el/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/pl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/bn/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/it/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/nb_NO/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/hu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/fr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/fa/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/hi_IN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/ar/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/pt_BR/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/sr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/hr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/es/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/uk_UA/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/ne/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/lv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/he/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/da/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/ca/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/de/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/mk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/cs/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/sk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/ru/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/ko/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/zh_TW/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/eo/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/zh_CN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/tr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/pt_PT/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/cy/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/eu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/nl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/pt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/ja/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/vi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/hi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/id/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/sl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/devhelp/locales/lt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/sv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/si/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/et/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/ta/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/fi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/ro/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/sr@latin/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/el/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/pl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/bn/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/it/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/nb_NO/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/hu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/fr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/fa/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/hi_IN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/ar/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/pt_BR/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/sr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/hr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/es/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/uk_UA/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/ne/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/lv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/he/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/da/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/ca/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/de/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/mk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/cs/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/sk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/ru/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/ko/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/zh_TW/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/eo/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/zh_CN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/tr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/pt_PT/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/cy/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/eu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/nl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/pt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/ja/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/vi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/hi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/id/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/sl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/qthelp/locales/lt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/sv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/si/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/et/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/ta/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/fi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/ro/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/sr@latin/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/el/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/ur/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/pl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/bn/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/it/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/nb_NO/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/hu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/fr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/fa/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/hi_IN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/ar/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/pt_BR/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/sr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/hr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/es/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/uk_UA/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/cak/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/ne/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/lv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/he/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/da/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/ca/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/de/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/mk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/cs/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/sk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/ru/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/ko/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/zh_TW/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/eo/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/zh_CN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/tr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/pt_PT/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/cy/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/eu/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/nl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/pt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/ja/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/vi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/hi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/id/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/sl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/sphinxcontrib/applehelp/locales/lt/LC_MESSAGES\n",
            "184K\t/usr/local/lib/python3.10/dist-packages/nbclassic/i18n/fr_FR/LC_MESSAGES\n",
            "212K\t/usr/local/lib/python3.10/dist-packages/nbclassic/i18n/ja_JP/LC_MESSAGES\n",
            "180K\t/usr/local/lib/python3.10/dist-packages/nbclassic/i18n/zh_CN/LC_MESSAGES\n",
            "188K\t/usr/local/lib/python3.10/dist-packages/nbclassic/i18n/nl/LC_MESSAGES\n",
            "236K\t/usr/local/lib/python3.10/dist-packages/nbclassic/i18n/ru_RU/LC_MESSAGES\n",
            "56K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/autoload\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size1/Regular\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size1\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Variants/BoldItalic\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Variants/Bold\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Variants/Regular\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Variants/Italic\n",
            "124K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Variants\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Symbols/Bold\n",
            "52K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Symbols/Regular\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Symbols\n",
            "112K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Latin/BoldItalic\n",
            "100K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Latin/Bold\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Latin/Regular\n",
            "116K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Latin/Italic\n",
            "436K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Latin\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/SansSerif/BoldItalic\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/SansSerif/Bold\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/SansSerif/Regular\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/SansSerif/Italic\n",
            "132K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/SansSerif\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Shapes/BoldItalic\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Shapes/Bold\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Shapes/Regular\n",
            "116K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Shapes\n",
            "52K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Operators/Bold\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Operators/Regular\n",
            "164K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Operators\n",
            "76K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Misc/BoldItalic\n",
            "76K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Misc/Bold\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Misc/Regular\n",
            "76K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Misc/Italic\n",
            "340K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Misc\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Main/BoldItalic\n",
            "120K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Main/Bold\n",
            "136K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Main/Regular\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Main/Italic\n",
            "396K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Main\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size3/Regular\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size3\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Arrows/Bold\n",
            "76K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Arrows/Regular\n",
            "96K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Arrows\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Script/BoldItalic\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Script/Regular\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Script/Italic\n",
            "120K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Script\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Fraktur/Bold\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Fraktur/Regular\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Fraktur\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Normal/BoldItalic\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Normal/Bold\n",
            "44K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Normal/Italic\n",
            "140K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Normal\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size4/Regular\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size4\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size2/Regular\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size2\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/DoubleStruck/BoldItalic\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/DoubleStruck/Bold\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/DoubleStruck/Regular\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/DoubleStruck/Italic\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/DoubleStruck\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size5/Regular\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Size5\n",
            "80K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Alphabets/BoldItalic\n",
            "68K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Alphabets/Bold\n",
            "72K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Alphabets/Regular\n",
            "80K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Alphabets/Italic\n",
            "304K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Alphabets\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Marks/BoldItalic\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Marks/Bold\n",
            "40K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Marks/Regular\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Marks/Italic\n",
            "116K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Marks\n",
            "28K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Monospace/Regular\n",
            "32K\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web/Monospace\n",
            "2.9M\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts/STIX-Web\n",
            "2.9M\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG/fonts\n",
            "3.0M\t/usr/local/lib/python3.10/dist-packages/nbclassic/static/components/MathJax/jax/output/SVG\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/es_ES/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/ko_KR/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/id_ID/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/sv_SE/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/ca_ES/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/ar/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/pt_BR/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/uk_UA/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/zh_HK/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/fr_FR/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/fa_IR/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/sk_SK/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/nl_NL/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/de_DE/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/pl_PL/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/fi_FI/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/vi_VN/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/ja_JP/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/eo/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/da_DK/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/zh_CN/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/sl_SI/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/tr_TR/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/pt_PT/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/eu/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/el_GR/LC_MESSAGES\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/el_GR\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/it_IT/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/ru_RU/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/humanize/locale/bn_BD/LC_MESSAGES\n",
            "456K\t/usr/local/lib/python3.10/dist-packages/PyOpenGL-3.1.7.dist-info\n",
            "104K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/Eigen/src/Core/arch/GPU\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/Eigen/src/Geometry/arch\n",
            "264K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/Eigen/src/Geometry\n",
            "100K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/triton/lib/Conversion/TritonGPUToLLVM\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/triton/include/triton/Conversion/TritonToTritonGPU\n",
            "48K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/triton/include/triton/Conversion/TritonGPUToLLVM\n",
            "256K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/triton/include/triton/Dialect/TritonGPU/IR\n",
            "60K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/triton/include/triton/Dialect/TritonGPU/Transforms\n",
            "320K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/triton/include/triton/Dialect/TritonGPU\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/_virtual_includes/GPUToROCDLTGen\n",
            "164K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/_virtual_includes/ArithCanonicalizationIncGen\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/_virtual_includes/GPUToNVVMGen\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/_virtual_includes/ShapeToStandardGen\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/_virtual_includes/MLIRShapeCanonicalizationIncGen\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/lib/Conversion/GPUToROCDL\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/lib/Conversion/GPUToNVVM\n",
            "24K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/lib/Conversion/GPUCommon\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Conversion/GPUToROCDL\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Conversion/GPUToNVVM\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Conversion/GPUCommon\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Conversion/SCFToGPU\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Conversion/AMDGPUToROCDL\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Target/LLVMIR/Dialect/GPU\n",
            "464K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Dialect/NVGPU/IR\n",
            "468K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Dialect/NVGPU\n",
            "524K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Dialect/AMDGPU/IR\n",
            "8.0K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Dialect/AMDGPU/Utils\n",
            "536K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Dialect/AMDGPU\n",
            "1.5M\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Dialect/GPU/IR\n",
            "88K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Dialect/GPU/Transforms\n",
            "1.6M\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/external/llvm-project/mlir/include/mlir/Dialect/GPU\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/tensorflow/include/unsupported/Eigen/src/SpecialFunctions/arch/GPU\n",
            "1.4G\t/usr/local/lib/python3.10/dist-packages/tensorflow\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/sv/LC_MESSAGES\n",
            "484K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/uk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/tet/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/et/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/fi/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/hy/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/ro/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/ms/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/bs/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/el/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/am/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/pl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/en_CA/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/be/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/it/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/is/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/hu/LC_MESSAGES\n",
            "76K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/fr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/fa/LC_MESSAGES\n",
            "92K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/ar/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/sr/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/hr/LC_MESSAGES\n",
            "140K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/es/LC_MESSAGES\n",
            "732K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/en_US/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/no/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/pt_MZ/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/lv/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/bg/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/to/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/lb/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/en_CY/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/he/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/da/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/uz/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/pt_AO/LC_MESSAGES\n",
            "52K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/de/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/pt_TL/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/cs/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/sk/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/ka/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/ru/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/ko/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/pap/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/sw/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/zh_TW/LC_MESSAGES\n",
            "20K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/zh_CN/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/tr/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/km/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/mt/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/pt_PT/LC_MESSAGES\n",
            "108K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/th/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/mg/LC_MESSAGES\n",
            "36K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/nl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/ja/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/id/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/az/LC_MESSAGES\n",
            "16K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/lo/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/sl/LC_MESSAGES\n",
            "12K\t/usr/local/lib/python3.10/dist-packages/holidays/locale/lt/LC_MESSAGES\n",
            "11G\t/usr/local/lib/python3.10/dist-packages\n",
            "11G\t/usr/local/lib/python3.10\n",
            "12G\t/usr/local/lib\n",
            "4.0G\t/usr/local/cuda-12.2/targets/x86_64-linux/lib\n",
            "4.0G\t/usr/local/cuda-12.2/targets/x86_64-linux\n",
            "4.0G\t/usr/local/cuda-12.2/targets\n",
            "56K\t/usr/local/cuda-12.2/compute-sanitizer/docs/SanitizerApiGuide\n",
            "52K\t/usr/local/cuda-12.2/compute-sanitizer/docs/SanitizerNvtxGuide\n",
            "4.4G\t/usr/local/cuda-12.2\n",
            "16G\t/usr/local\n",
            "40K\t/usr/share/perl5/Debconf/Element/Gnome\n",
            "8.0K\t/usr/share/perl5/Git/LoadCPAN/Mail\n",
            "16K\t/usr/share/perl5/Git/LoadCPAN\n",
            "40K\t/usr/share/perl5/Git\n",
            "44K\t/usr/share/doc/git/contrib/buildsystems/Generators\n",
            "708K\t/usr/share/locale/sv/LC_MESSAGES\n",
            "940K\t/usr/share/locale/uk/LC_MESSAGES\n",
            "48K\t/usr/share/locale/af/LC_MESSAGES\n",
            "124K\t/usr/share/locale/et/LC_MESSAGES\n",
            "120K\t/usr/share/locale/nb/LC_MESSAGES\n",
            "140K\t/usr/share/locale/fi/LC_MESSAGES\n",
            "156K\t/usr/share/locale/ro/LC_MESSAGES\n",
            "32K\t/usr/share/locale/ms/LC_MESSAGES\n",
            "52K\t/usr/share/locale/bs/LC_MESSAGES\n",
            "224K\t/usr/share/locale/el/LC_MESSAGES\n",
            "444K\t/usr/share/locale/pl/LC_MESSAGES\n",
            "428K\t/usr/share/locale/gl/LC_MESSAGES\n",
            "324K\t/usr/share/locale/be/LC_MESSAGES\n",
            "712K\t/usr/share/locale/it/LC_MESSAGES\n",
            "276K\t/usr/share/locale/hu/LC_MESSAGES\n",
            "756K\t/usr/share/locale/fr/LC_MESSAGES\n",
            "104K\t/usr/share/locale/ar/LC_MESSAGES\n",
            "152K\t/usr/share/locale/pt_BR/LC_MESSAGES\n",
            "268K\t/usr/share/locale/sr/LC_MESSAGES\n",
            "160K\t/usr/share/locale/hr/LC_MESSAGES\n",
            "224K\t/usr/share/locale/es/LC_MESSAGES\n",
            "92K\t/usr/share/locale/ne/LC_MESSAGES\n",
            "168K\t/usr/share/locale/bg/LC_MESSAGES\n",
            "72K\t/usr/share/locale/ga/LC_MESSAGES\n",
            "312K\t/usr/share/locale/da/LC_MESSAGES\n",
            "192K\t/usr/share/locale/ca/LC_MESSAGES\n",
            "800K\t/usr/share/locale/de/LC_MESSAGES\n",
            "436K\t/usr/share/locale/ast/LC_MESSAGES\n",
            "484K\t/usr/share/locale/pa/LC_MESSAGES\n",
            "188K\t/usr/share/locale/cs/LC_MESSAGES\n",
            "64K\t/usr/share/locale/oc/LC_MESSAGES\n",
            "152K\t/usr/share/locale/sk/LC_MESSAGES\n",
            "40K\t/usr/share/locale/ia/LC_MESSAGES\n",
            "16K\t/usr/share/locale/ku/LC_MESSAGES\n",
            "356K\t/usr/share/locale/ru/LC_MESSAGES\n",
            "96K\t/usr/share/locale/nn/LC_MESSAGES\n",
            "156K\t/usr/share/locale/ko/LC_MESSAGES\n",
            "176K\t/usr/share/locale/zh_TW/LC_MESSAGES\n",
            "184K\t/usr/share/locale/eo/LC_MESSAGES\n",
            "288K\t/usr/share/locale/zh_CN/LC_MESSAGES\n",
            "580K\t/usr/share/locale/tr/LC_MESSAGES\n",
            "108K\t/usr/share/locale/km/LC_MESSAGES\n",
            "40K\t/usr/share/locale/kk/LC_MESSAGES\n",
            "564K\t/usr/share/locale/mr/LC_MESSAGES\n",
            "80K\t/usr/share/locale/cy/LC_MESSAGES\n",
            "156K\t/usr/share/locale/eu/LC_MESSAGES\n",
            "320K\t/usr/share/locale/th/LC_MESSAGES\n",
            "72K\t/usr/share/locale/tl/LC_MESSAGES\n",
            "420K\t/usr/share/locale/nl/LC_MESSAGES\n",
            "152K\t/usr/share/locale/pt/LC_MESSAGES\n",
            "284K\t/usr/share/locale/ja/LC_MESSAGES\n",
            "124K\t/usr/share/locale/dz/LC_MESSAGES\n",
            "308K\t/usr/share/locale/vi/LC_MESSAGES\n",
            "544K\t/usr/share/locale/id/LC_MESSAGES\n",
            "224K\t/usr/share/locale/sl/LC_MESSAGES\n",
            "204K\t/usr/share/locale/lt/LC_MESSAGES\n",
            "32K\t/usr/share/locale/wo/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/sd/LC_MESSAGES\n",
            "44K\t/usr/share/locale/si/LC_MESSAGES\n",
            "464K\t/usr/share/locale/kn/LC_MESSAGES\n",
            "520K\t/usr/share/locale/ta/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/zh_Hans/LC_MESSAGES\n",
            "28K\t/usr/share/locale/mi/LC_MESSAGES\n",
            "12K\t/usr/share/locale/chr/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/ak/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/an/LC_MESSAGES\n",
            "12K\t/usr/share/locale/nah/LC_MESSAGES\n",
            "40K\t/usr/share/locale/ug/LC_MESSAGES\n",
            "40K\t/usr/share/locale/hy/LC_MESSAGES\n",
            "80K\t/usr/share/locale/br/LC_MESSAGES\n",
            "40K\t/usr/share/locale/ky/LC_MESSAGES\n",
            "216K\t/usr/share/locale/sr@latin/LC_MESSAGES\n",
            "28K\t/usr/share/locale/tk/LC_MESSAGES\n",
            "48K\t/usr/share/locale/tt/LC_MESSAGES\n",
            "12K\t/usr/share/locale/zh_Hant/LC_MESSAGES\n",
            "16K\t/usr/share/locale/io/LC_MESSAGES\n",
            "16K\t/usr/share/locale/dv/LC_MESSAGES\n",
            "16K\t/usr/share/locale/ach/LC_MESSAGES\n",
            "24K\t/usr/share/locale/ps/LC_MESSAGES\n",
            "80K\t/usr/share/locale/as/LC_MESSAGES\n",
            "16K\t/usr/share/locale/kw/LC_MESSAGES\n",
            "16K\t/usr/share/locale/ur/LC_MESSAGES\n",
            "32K\t/usr/share/locale/am/LC_MESSAGES\n",
            "16K\t/usr/share/locale/jam/LC_MESSAGES\n",
            "16K\t/usr/share/locale/frp/LC_MESSAGES\n",
            "28K\t/usr/share/locale/cv/LC_MESSAGES\n",
            "312K\t/usr/share/locale/crh/LC_MESSAGES\n",
            "40K\t/usr/share/locale/fil/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/ay/LC_MESSAGES\n",
            "188K\t/usr/share/locale/bn/LC_MESSAGES\n",
            "40K\t/usr/share/locale/tg/LC_MESSAGES\n",
            "248K\t/usr/share/locale/is/LC_MESSAGES\n",
            "12K\t/usr/share/locale/nb_NO/LC_MESSAGES\n",
            "44K\t/usr/share/locale/tt@iqtelif/LC_MESSAGES\n",
            "76K\t/usr/share/locale/fa/LC_MESSAGES\n",
            "12K\t/usr/share/locale/ht/LC_MESSAGES\n",
            "28K\t/usr/share/locale/nso/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/mo/LC_MESSAGES\n",
            "68K\t/usr/share/locale/fur/LC_MESSAGES\n",
            "44K\t/usr/share/locale/mn/LC_MESSAGES\n",
            "20K\t/usr/share/locale/my/LC_MESSAGES\n",
            "68K\t/usr/share/locale/zh_HK/LC_MESSAGES\n",
            "20K\t/usr/share/locale/tzm/LC_MESSAGES\n",
            "92K\t/usr/share/locale/lv/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/ch/LC_MESSAGES\n",
            "92K\t/usr/share/locale/he/LC_MESSAGES\n",
            "120K\t/usr/share/locale/gu/LC_MESSAGES\n",
            "12K\t/usr/share/locale/nv/LC_MESSAGES\n",
            "12K\t/usr/share/locale/mhr/LC_MESSAGES\n",
            "16K\t/usr/share/locale/yo/LC_MESSAGES\n",
            "20K\t/usr/share/locale/xh/LC_MESSAGES\n",
            "32K\t/usr/share/locale/gez/LC_MESSAGES\n",
            "12K\t/usr/share/locale/ha/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/bi/LC_MESSAGES\n",
            "16K\t/usr/share/locale/uz/LC_MESSAGES\n",
            "12K\t/usr/share/locale/csb/LC_MESSAGES\n",
            "44K\t/usr/share/locale/mk/LC_MESSAGES\n",
            "32K\t/usr/share/locale/byn/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/ace/LC_MESSAGES\n",
            "72K\t/usr/share/locale/rw/LC_MESSAGES\n",
            "20K\t/usr/share/locale/kok/LC_MESSAGES\n",
            "16K\t/usr/share/locale/en@boldquot/LC_MESSAGES\n",
            "12K\t/usr/share/locale/haw/LC_MESSAGES\n",
            "16K\t/usr/share/locale/wal/LC_MESSAGES\n",
            "296K\t/usr/share/locale/or/LC_MESSAGES\n",
            "48K\t/usr/share/locale/ka/LC_MESSAGES\n",
            "28K\t/usr/share/locale/ve/LC_MESSAGES\n",
            "16K\t/usr/share/locale/fo/LC_MESSAGES\n",
            "40K\t/usr/share/locale/kab/LC_MESSAGES\n",
            "12K\t/usr/share/locale/bar/LC_MESSAGES\n",
            "12K\t/usr/share/locale/na/LC_MESSAGES\n",
            "48K\t/usr/share/locale/bn_IN/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/ba/LC_MESSAGES\n",
            "88K\t/usr/share/locale/ml/LC_MESSAGES\n",
            "16K\t/usr/share/locale/pi/LC_MESSAGES\n",
            "16K\t/usr/share/locale/gn/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/pap/LC_MESSAGES\n",
            "16K\t/usr/share/locale/sw/LC_MESSAGES\n",
            "16K\t/usr/share/locale/son/LC_MESSAGES\n",
            "32K\t/usr/share/locale/kmr/LC_MESSAGES\n",
            "16K\t/usr/share/locale/ckb/LC_MESSAGES\n",
            "76K\t/usr/share/locale/wa/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/ff/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/ee/LC_MESSAGES\n",
            "212K\t/usr/share/locale/sc/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/iu/LC_MESSAGES\n",
            "44K\t/usr/share/locale/mt/LC_MESSAGES\n",
            "80K\t/usr/share/locale/te/LC_MESSAGES\n",
            "24K\t/usr/share/locale/zu/LC_MESSAGES\n",
            "36K\t/usr/share/locale/ti/LC_MESSAGES\n",
            "56K\t/usr/share/locale/sq/LC_MESSAGES\n",
            "16K\t/usr/share/locale/fy/LC_MESSAGES\n",
            "32K\t/usr/share/locale/tig/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/ab/LC_MESSAGES\n",
            "12K\t/usr/share/locale/kv/LC_MESSAGES\n",
            "8.0K\t/usr/share/locale/kl/LC_MESSAGES\n",
            "16K\t/usr/share/locale/gv/LC_MESSAGES\n",
            "68K\t/usr/share/locale/hi/LC_MESSAGES\n",
            "96K\t/usr/share/locale/en/LC_MESSAGES\n",
            "32K\t/usr/share/locale/bn_BD/LC_MESSAGES\n",
            "12K\t/usr/share/locale/ki/LC_MESSAGES\n",
            "32K\t/usr/share/locale/az/LC_MESSAGES\n",
            "12K\t/usr/share/locale/lo/LC_MESSAGES\n",
            "32K\t/usr/share/locale/so/LC_MESSAGES\n",
            "16K\t/usr/share/locale/ce/LC_MESSAGES\n",
            "12K\t/usr/share/locale/mai/LC_MESSAGES\n",
            "16K\t/usr/share/locale/en@quot/LC_MESSAGES\n",
            "128K\t/usr/share/X11/locale/el_GR.UTF-8\n",
            "180K\t/usr/share/vim/vim82/lang/ko.UTF-8/LC_MESSAGES\n",
            "144K\t/usr/share/vim/vim82/lang/sv/LC_MESSAGES\n",
            "220K\t/usr/share/vim/vim82/lang/uk/LC_MESSAGES\n",
            "124K\t/usr/share/vim/vim82/lang/af/LC_MESSAGES\n",
            "168K\t/usr/share/vim/vim82/lang/pl.cp1250/LC_MESSAGES\n",
            "128K\t/usr/share/vim/vim82/lang/zh_CN.cp936/LC_MESSAGES\n",
            "144K\t/usr/share/vim/vim82/lang/nb/LC_MESSAGES\n",
            "136K\t/usr/share/vim/vim82/lang/zh_CN.UTF-8/LC_MESSAGES\n",
            "176K\t/usr/share/vim/vim82/lang/fi/LC_MESSAGES\n",
            "168K\t/usr/share/vim/vim82/lang/pl/LC_MESSAGES\n",
            "272K\t/usr/share/vim/vim82/lang/it/LC_MESSAGES\n",
            "208K\t/usr/share/vim/vim82/lang/fr/LC_MESSAGES\n",
            "180K\t/usr/share/vim/vim82/lang/pt_BR/LC_MESSAGES\n",
            "328K\t/usr/share/vim/vim82/lang/sr/LC_MESSAGES\n",
            "160K\t/usr/share/vim/vim82/lang/es/LC_MESSAGES\n",
            "144K\t/usr/share/vim/vim82/lang/no/LC_MESSAGES\n",
            "16K\t/usr/share/vim/vim82/lang/lv/LC_MESSAGES\n",
            "180K\t/usr/share/vim/vim82/lang/ga/LC_MESSAGES\n",
            "176K\t/usr/share/vim/vim82/lang/da/LC_MESSAGES\n",
            "180K\t/usr/share/vim/vim82/lang/ca/LC_MESSAGES\n",
            "272K\t/usr/share/vim/vim82/lang/de/LC_MESSAGES\n",
            "108K\t/usr/share/vim/vim82/lang/cs.cp1250/LC_MESSAGES\n",
            "120K\t/usr/share/vim/vim82/lang/zh_TW.UTF-8/LC_MESSAGES\n",
            "108K\t/usr/share/vim/vim82/lang/cs/LC_MESSAGES\n",
            "144K\t/usr/share/vim/vim82/lang/sk/LC_MESSAGES\n",
            "172K\t/usr/share/vim/vim82/lang/pl.UTF-8/LC_MESSAGES\n",
            "244K\t/usr/share/vim/vim82/lang/ru/LC_MESSAGES\n",
            "164K\t/usr/share/vim/vim82/lang/ko/LC_MESSAGES\n",
            "112K\t/usr/share/vim/vim82/lang/zh_TW/LC_MESSAGES\n",
            "216K\t/usr/share/vim/vim82/lang/eo/LC_MESSAGES\n",
            "176K\t/usr/share/vim/vim82/lang/uk.cp1251/LC_MESSAGES\n",
            "184K\t/usr/share/vim/vim82/lang/ja.sjis/LC_MESSAGES\n",
            "128K\t/usr/share/vim/vim82/lang/zh_CN/LC_MESSAGES\n",
            "276K\t/usr/share/vim/vim82/lang/tr/LC_MESSAGES\n",
            "144K\t/usr/share/vim/vim82/lang/sk.cp1250/LC_MESSAGES\n",
            "192K\t/usr/share/vim/vim82/lang/ru.cp1251/LC_MESSAGES\n",
            "24K\t/usr/share/vim/vim82/lang/en_GB/LC_MESSAGES\n",
            "28K\t/usr/share/vim/vim82/lang/en_GB\n",
            "184K\t/usr/share/vim/vim82/lang/ja.euc-jp/LC_MESSAGES\n",
            "108K\t/usr/share/vim/vim82/lang/nl/LC_MESSAGES\n",
            "212K\t/usr/share/vim/vim82/lang/ja/LC_MESSAGES\n",
            "140K\t/usr/share/vim/vim82/lang/vi/LC_MESSAGES\n",
            "8.0K\t/usr/share/cmake-3.22/Modules/UseSWIG\n",
            "168K\t/usr/share/perl/5.34.0/unicore/lib/Gc\n",
            "12K\t/usr/share/perl/5.34.0/unicore/lib/GrExt\n",
            "44K\t/usr/share/perl/5.34.0/unicore/lib/GCB\n",
            "16K\t/usr/share/perl/5.34.0/unicore/lib/GrBase\n",
            "8.0K\t/usr/share/perl/5.34.0/IO/Compress/Gzip\n",
            "100K\t/usr/share/perl/5.34.0/Getopt\n",
            "56K\t/usr/src/python3.10/Grammar\n",
            "36K\t/usr/lib/x86_64-linux-gnu/perl-base/auto/File/Glob\n",
            "168K\t/usr/lib/x86_64-linux-gnu/perl-base/unicore/lib/Gc\n",
            "12K\t/usr/lib/x86_64-linux-gnu/perl-base/unicore/lib/GrExt\n",
            "44K\t/usr/lib/x86_64-linux-gnu/perl-base/unicore/lib/GCB\n",
            "16K\t/usr/lib/x86_64-linux-gnu/perl-base/unicore/lib/GrBase\n",
            "48K\t/usr/lib/x86_64-linux-gnu/perl-base/Getopt\n",
            "24K\t/usr/lib/x86_64-linux-gnu/cmake/GEOS\n",
            "44K\t/usr/lib/x86_64-linux-gnu/perl/5.34.0/auto/GDBM_File\n",
            "36K\t/usr/lib/x86_64-linux-gnu/perl/5.34.0/auto/File/Glob\n",
            "20K\t/usr/lib/x86_64-linux-gnu/perl/5.34.0/auto/File/DosGlob\n",
            "5.8G\t/usr/lib/x86_64-linux-gnu\n",
            "8.0K\t/usr/lib/locale/C.utf8/LC_MESSAGES\n",
            "24K\t/usr/lib/python3/dist-packages/PyGObject-3.42.1.egg-info\n",
            "684K\t/usr/lib/R/library/translations/pl/LC_MESSAGES\n",
            "704K\t/usr/lib/R/library/translations/it/LC_MESSAGES\n",
            "736K\t/usr/lib/R/library/translations/fr/LC_MESSAGES\n",
            "44K\t/usr/lib/R/library/translations/fa/LC_MESSAGES\n",
            "356K\t/usr/lib/R/library/translations/pt_BR/LC_MESSAGES\n",
            "148K\t/usr/lib/R/library/translations/es/LC_MESSAGES\n",
            "244K\t/usr/lib/R/library/translations/da/LC_MESSAGES\n",
            "648K\t/usr/lib/R/library/translations/de/LC_MESSAGES\n",
            "732K\t/usr/lib/R/library/translations/ru/LC_MESSAGES\n",
            "192K\t/usr/lib/R/library/translations/nn/LC_MESSAGES\n",
            "596K\t/usr/lib/R/library/translations/ko/LC_MESSAGES\n",
            "596K\t/usr/lib/R/library/translations/zh_TW/LC_MESSAGES\n",
            "524K\t/usr/lib/R/library/translations/zh_CN/LC_MESSAGES\n",
            "204K\t/usr/lib/R/library/translations/tr/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/translations/en_GB/LC_MESSAGES\n",
            "20K\t/usr/lib/R/library/translations/en_GB\n",
            "692K\t/usr/lib/R/library/translations/ja/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/translations/en/LC_MESSAGES\n",
            "688K\t/usr/lib/R/library/translations/lt/LC_MESSAGES\n",
            "656K\t/usr/lib/R/library/translations/en@quot/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/class/po/pl/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/class/po/it/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/class/po/fr/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/class/po/de/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/class/po/ko/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/class/po/en@quot/LC_MESSAGES\n",
            "36K\t/usr/lib/R/library/foreign/po/pl/LC_MESSAGES\n",
            "36K\t/usr/lib/R/library/foreign/po/it/LC_MESSAGES\n",
            "36K\t/usr/lib/R/library/foreign/po/fr/LC_MESSAGES\n",
            "36K\t/usr/lib/R/library/foreign/po/de/LC_MESSAGES\n",
            "36K\t/usr/lib/R/library/foreign/po/en@quot/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/MASS/po/pl/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/MASS/po/it/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/MASS/po/fr/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/MASS/po/de/LC_MESSAGES\n",
            "20K\t/usr/lib/R/library/MASS/po/ko/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/MASS/po/en@quot/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/nnet/po/pl/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/nnet/po/it/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/nnet/po/fr/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/nnet/po/de/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/nnet/po/ko/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/nnet/po/en@quot/LC_MESSAGES\n",
            "28K\t/usr/lib/R/library/Matrix/po/pl/LC_MESSAGES\n",
            "32K\t/usr/lib/R/library/Matrix/po/it/LC_MESSAGES\n",
            "32K\t/usr/lib/R/library/Matrix/po/fr/LC_MESSAGES\n",
            "28K\t/usr/lib/R/library/Matrix/po/de/LC_MESSAGES\n",
            "32K\t/usr/lib/R/library/Matrix/po/ko/LC_MESSAGES\n",
            "28K\t/usr/lib/R/library/Matrix/po/lt/LC_MESSAGES\n",
            "60K\t/usr/lib/R/library/Matrix/po/en@quot/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/KernSmooth/po/pl/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/KernSmooth/po/it/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/KernSmooth/po/fr/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/KernSmooth/po/de/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/KernSmooth/po/ko/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/KernSmooth/po/en@quot/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/boot/po/pl/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/boot/po/it/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/boot/po/fr/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/boot/po/de/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/boot/po/ru/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/boot/po/ko/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/boot/po/en@quot/LC_MESSAGES\n",
            "40K\t/usr/lib/R/library/mgcv/po/pl/LC_MESSAGES\n",
            "60K\t/usr/lib/R/library/mgcv/po/fr/LC_MESSAGES\n",
            "60K\t/usr/lib/R/library/mgcv/po/de/LC_MESSAGES\n",
            "32K\t/usr/lib/R/library/mgcv/po/ko/LC_MESSAGES\n",
            "56K\t/usr/lib/R/library/mgcv/po/en@quot/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/spatial/po/pl/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/spatial/po/it/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/spatial/po/fr/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/spatial/po/de/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/spatial/po/ko/LC_MESSAGES\n",
            "8.0K\t/usr/lib/R/library/spatial/po/en@quot/LC_MESSAGES\n",
            "52K\t/usr/lib/R/library/nlme/po/pl/LC_MESSAGES\n",
            "52K\t/usr/lib/R/library/nlme/po/fr/LC_MESSAGES\n",
            "56K\t/usr/lib/R/library/nlme/po/de/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/nlme/po/ko/LC_MESSAGES\n",
            "52K\t/usr/lib/R/library/nlme/po/en@quot/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/cluster/po/pl/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/cluster/po/it/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/cluster/po/fr/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/cluster/po/de/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/cluster/po/ko/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/cluster/po/lt/LC_MESSAGES\n",
            "24K\t/usr/lib/R/library/cluster/po/en@quot/LC_MESSAGES\n",
            "20K\t/usr/lib/R/library/lattice/po/pl/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/lattice/po/it/LC_MESSAGES\n",
            "20K\t/usr/lib/R/library/lattice/po/fr/LC_MESSAGES\n",
            "20K\t/usr/lib/R/library/lattice/po/de/LC_MESSAGES\n",
            "20K\t/usr/lib/R/library/lattice/po/ko/LC_MESSAGES\n",
            "20K\t/usr/lib/R/library/lattice/po/en@quot/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/rpart/po/pl/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/rpart/po/fr/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/rpart/po/de/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/rpart/po/ru/LC_MESSAGES\n",
            "20K\t/usr/lib/R/library/rpart/po/ko/LC_MESSAGES\n",
            "16K\t/usr/lib/R/library/rpart/po/en@quot/LC_MESSAGES\n",
            "232K\t/usr/lib/R/site-library/data.table/po/zh_CN/LC_MESSAGES\n",
            "240K\t/usr/lib/R/site-library/data.table/po/en@quot/LC_MESSAGES\n",
            "156K\t/usr/lib/llvm-14/include/polly/CodeGen\n",
            "6.7G\t/usr/lib\n",
            "12K\t/usr/include/GL/internal\n",
            "120K\t/usr/include/GL\n",
            "24G\t/usr\n",
            "14G\t/content/merge\n",
            "14G\t/content\n",
            "388K\t/tools/google-cloud-sdk/platform/gsutil/third_party/chardet/tests/GB2312\n",
            "1.1G\t/tools\n",
            "43G\t/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Llama.cpp install\n",
        "! git clone https://github.com/ggerganov/llama.cpp\n",
        "! cd llama.cpp && make\n",
        "! python3 -m pip install -r llama.cpp/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNm-76uQfM7G",
        "outputId": "47e8b574-b708-4e46-e700-335b2044a0a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 16800, done.\u001b[K\n",
            "remote: Counting objects: 100% (6191/6191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (348/348), done.\u001b[K\n",
            "remote: Total 16800 (delta 6039), reused 5882 (delta 5843), pack-reused 10609\u001b[K\n",
            "Receiving objects: 100% (16800/16800), 19.04 MiB | 19.60 MiB/s, done.\n",
            "Resolving deltas: 100% (11729/11729), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting to Llama.cpp format\n",
        "!python3 llama.cpp/convert.py merge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyvhnl1gnvWo",
        "outputId": "bb4bd801-6c2c-4051-f330-4976d5763bd1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model file merge/model-00001-of-00008.safetensors\n",
            "Loading model file merge/model-00001-of-00008.safetensors\n",
            "Loading model file merge/model-00002-of-00008.safetensors\n",
            "Loading model file merge/model-00003-of-00008.safetensors\n",
            "Loading model file merge/model-00004-of-00008.safetensors\n",
            "Loading model file merge/model-00005-of-00008.safetensors\n",
            "Loading model file merge/model-00006-of-00008.safetensors\n",
            "Loading model file merge/model-00007-of-00008.safetensors\n",
            "Loading model file merge/model-00008-of-00008.safetensors\n",
            "params = Params(n_vocab=32000, n_embd=4096, n_layer=32, n_ctx=32768, n_ff=14336, n_head=32, n_head_kv=8, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=10000.0, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=None, path_model=PosixPath('merge'))\n",
            "Found vocab files: {'tokenizer.model': PosixPath('merge/tokenizer.model'), 'vocab.json': None, 'tokenizer.json': PosixPath('merge/tokenizer.json')}\n",
            "Loading vocab file 'merge/tokenizer.model', type 'spm'\n",
            "Vocab info: <SentencePieceVocab with 32000 base tokens and 0 added tokens>\n",
            "Special vocab info: <SpecialVocab with 0 merges, special tokens {'bos': 1, 'eos': 2, 'unk': 0}, add special tokens unset>\n",
            "Permuting layer 0\n",
            "Permuting layer 1\n",
            "Permuting layer 2\n",
            "Permuting layer 3\n",
            "Permuting layer 4\n",
            "Permuting layer 5\n",
            "Permuting layer 6\n",
            "Permuting layer 7\n",
            "Permuting layer 8\n",
            "Permuting layer 9\n",
            "Permuting layer 10\n",
            "Permuting layer 11\n",
            "Permuting layer 12\n",
            "Permuting layer 13\n",
            "Permuting layer 14\n",
            "Permuting layer 15\n",
            "Permuting layer 16\n",
            "Permuting layer 17\n",
            "Permuting layer 18\n",
            "Permuting layer 19\n",
            "Permuting layer 20\n",
            "Permuting layer 21\n",
            "Permuting layer 22\n",
            "Permuting layer 23\n",
            "Permuting layer 24\n",
            "Permuting layer 25\n",
            "Permuting layer 26\n",
            "Permuting layer 27\n",
            "Permuting layer 28\n",
            "Permuting layer 29\n",
            "Permuting layer 30\n",
            "Permuting layer 31\n",
            "model.layers.17.post_attention_layernorm.weight  -> blk.17.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.17.self_attn.k_proj.weight          -> blk.17.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.17.self_attn.o_proj.weight          -> blk.17.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.17.self_attn.q_proj.weight          -> blk.17.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.17.self_attn.v_proj.weight          -> blk.17.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.18.input_layernorm.weight           -> blk.18.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.18.mlp.down_proj.weight             -> blk.18.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.18.mlp.gate_proj.weight             -> blk.18.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.18.mlp.up_proj.weight               -> blk.18.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.18.post_attention_layernorm.weight  -> blk.18.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.18.self_attn.k_proj.weight          -> blk.18.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.18.self_attn.o_proj.weight          -> blk.18.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.18.self_attn.q_proj.weight          -> blk.18.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.18.self_attn.v_proj.weight          -> blk.18.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.19.input_layernorm.weight           -> blk.19.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.19.mlp.down_proj.weight             -> blk.19.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.19.mlp.gate_proj.weight             -> blk.19.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.19.mlp.up_proj.weight               -> blk.19.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.19.post_attention_layernorm.weight  -> blk.19.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.19.self_attn.k_proj.weight          -> blk.19.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.19.self_attn.o_proj.weight          -> blk.19.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.19.self_attn.q_proj.weight          -> blk.19.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.19.self_attn.v_proj.weight          -> blk.19.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.20.input_layernorm.weight           -> blk.20.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.20.mlp.down_proj.weight             -> blk.20.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.20.mlp.gate_proj.weight             -> blk.20.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.20.mlp.up_proj.weight               -> blk.20.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.20.post_attention_layernorm.weight  -> blk.20.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.20.self_attn.k_proj.weight          -> blk.20.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.20.self_attn.o_proj.weight          -> blk.20.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.20.self_attn.q_proj.weight          -> blk.20.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.20.self_attn.v_proj.weight          -> blk.20.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.21.input_layernorm.weight           -> blk.21.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.21.mlp.down_proj.weight             -> blk.21.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.21.mlp.gate_proj.weight             -> blk.21.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.21.mlp.up_proj.weight               -> blk.21.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.21.post_attention_layernorm.weight  -> blk.21.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.21.self_attn.k_proj.weight          -> blk.21.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.21.self_attn.o_proj.weight          -> blk.21.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.21.self_attn.q_proj.weight          -> blk.21.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.21.self_attn.v_proj.weight          -> blk.21.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.22.self_attn.k_proj.weight          -> blk.22.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.22.self_attn.o_proj.weight          -> blk.22.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.22.self_attn.q_proj.weight          -> blk.22.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.22.self_attn.v_proj.weight          -> blk.22.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.13.mlp.down_proj.weight             -> blk.13.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.13.mlp.gate_proj.weight             -> blk.13.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.13.post_attention_layernorm.weight  -> blk.13.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.13.self_attn.k_proj.weight          -> blk.13.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.13.self_attn.o_proj.weight          -> blk.13.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.13.self_attn.q_proj.weight          -> blk.13.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.13.self_attn.v_proj.weight          -> blk.13.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.14.input_layernorm.weight           -> blk.14.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.14.mlp.down_proj.weight             -> blk.14.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.14.mlp.gate_proj.weight             -> blk.14.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.14.mlp.up_proj.weight               -> blk.14.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.14.post_attention_layernorm.weight  -> blk.14.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.14.self_attn.k_proj.weight          -> blk.14.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.14.self_attn.o_proj.weight          -> blk.14.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.14.self_attn.q_proj.weight          -> blk.14.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.14.self_attn.v_proj.weight          -> blk.14.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.15.input_layernorm.weight           -> blk.15.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.15.mlp.down_proj.weight             -> blk.15.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.15.mlp.gate_proj.weight             -> blk.15.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.15.mlp.up_proj.weight               -> blk.15.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.15.post_attention_layernorm.weight  -> blk.15.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.15.self_attn.k_proj.weight          -> blk.15.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.15.self_attn.o_proj.weight          -> blk.15.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.15.self_attn.q_proj.weight          -> blk.15.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.15.self_attn.v_proj.weight          -> blk.15.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.16.input_layernorm.weight           -> blk.16.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.16.mlp.down_proj.weight             -> blk.16.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.16.mlp.gate_proj.weight             -> blk.16.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.16.mlp.up_proj.weight               -> blk.16.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.16.post_attention_layernorm.weight  -> blk.16.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.16.self_attn.k_proj.weight          -> blk.16.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.16.self_attn.o_proj.weight          -> blk.16.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.16.self_attn.q_proj.weight          -> blk.16.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.16.self_attn.v_proj.weight          -> blk.16.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.17.input_layernorm.weight           -> blk.17.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.17.mlp.down_proj.weight             -> blk.17.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.17.mlp.gate_proj.weight             -> blk.17.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.17.mlp.up_proj.weight               -> blk.17.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.10.input_layernorm.weight           -> blk.10.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.10.mlp.down_proj.weight             -> blk.10.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.10.mlp.gate_proj.weight             -> blk.10.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.10.mlp.up_proj.weight               -> blk.10.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.10.post_attention_layernorm.weight  -> blk.10.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.10.self_attn.k_proj.weight          -> blk.10.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.10.self_attn.o_proj.weight          -> blk.10.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.10.self_attn.q_proj.weight          -> blk.10.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.10.self_attn.v_proj.weight          -> blk.10.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.11.input_layernorm.weight           -> blk.11.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.11.mlp.down_proj.weight             -> blk.11.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.11.mlp.gate_proj.weight             -> blk.11.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.11.mlp.up_proj.weight               -> blk.11.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.11.post_attention_layernorm.weight  -> blk.11.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.11.self_attn.k_proj.weight          -> blk.11.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.11.self_attn.o_proj.weight          -> blk.11.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.11.self_attn.q_proj.weight          -> blk.11.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.11.self_attn.v_proj.weight          -> blk.11.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.12.input_layernorm.weight           -> blk.12.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.12.mlp.down_proj.weight             -> blk.12.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.12.mlp.gate_proj.weight             -> blk.12.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.12.mlp.up_proj.weight               -> blk.12.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.12.post_attention_layernorm.weight  -> blk.12.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.12.self_attn.k_proj.weight          -> blk.12.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.12.self_attn.o_proj.weight          -> blk.12.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.12.self_attn.q_proj.weight          -> blk.12.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.12.self_attn.v_proj.weight          -> blk.12.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.13.input_layernorm.weight           -> blk.13.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.13.mlp.up_proj.weight               -> blk.13.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.8.post_attention_layernorm.weight   -> blk.8.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.8.self_attn.k_proj.weight           -> blk.8.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.8.self_attn.o_proj.weight           -> blk.8.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.8.self_attn.q_proj.weight           -> blk.8.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.8.self_attn.v_proj.weight           -> blk.8.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.9.input_layernorm.weight            -> blk.9.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.9.mlp.down_proj.weight              -> blk.9.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.9.mlp.gate_proj.weight              -> blk.9.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.9.mlp.up_proj.weight                -> blk.9.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "model.layers.9.post_attention_layernorm.weight   -> blk.9.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.9.self_attn.k_proj.weight           -> blk.9.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.9.self_attn.o_proj.weight           -> blk.9.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.9.self_attn.q_proj.weight           -> blk.9.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.9.self_attn.v_proj.weight           -> blk.9.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.4.mlp.down_proj.weight              -> blk.4.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.4.mlp.gate_proj.weight              -> blk.4.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.4.post_attention_layernorm.weight   -> blk.4.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.4.self_attn.k_proj.weight           -> blk.4.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.4.self_attn.o_proj.weight           -> blk.4.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.4.self_attn.q_proj.weight           -> blk.4.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.4.self_attn.v_proj.weight           -> blk.4.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.5.input_layernorm.weight            -> blk.5.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.5.mlp.down_proj.weight              -> blk.5.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.5.mlp.gate_proj.weight              -> blk.5.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.5.mlp.up_proj.weight                -> blk.5.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "model.layers.5.post_attention_layernorm.weight   -> blk.5.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.5.self_attn.k_proj.weight           -> blk.5.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.5.self_attn.o_proj.weight           -> blk.5.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.5.self_attn.q_proj.weight           -> blk.5.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.5.self_attn.v_proj.weight           -> blk.5.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.6.input_layernorm.weight            -> blk.6.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.6.mlp.down_proj.weight              -> blk.6.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.6.mlp.gate_proj.weight              -> blk.6.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.6.mlp.up_proj.weight                -> blk.6.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "model.layers.6.post_attention_layernorm.weight   -> blk.6.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.6.self_attn.k_proj.weight           -> blk.6.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.6.self_attn.o_proj.weight           -> blk.6.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.6.self_attn.q_proj.weight           -> blk.6.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.6.self_attn.v_proj.weight           -> blk.6.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.7.input_layernorm.weight            -> blk.7.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.7.mlp.down_proj.weight              -> blk.7.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.7.mlp.gate_proj.weight              -> blk.7.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.7.mlp.up_proj.weight                -> blk.7.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "model.layers.7.post_attention_layernorm.weight   -> blk.7.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.7.self_attn.k_proj.weight           -> blk.7.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.7.self_attn.o_proj.weight           -> blk.7.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.7.self_attn.q_proj.weight           -> blk.7.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.7.self_attn.v_proj.weight           -> blk.7.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.8.input_layernorm.weight            -> blk.8.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.8.mlp.down_proj.weight              -> blk.8.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.8.mlp.gate_proj.weight              -> blk.8.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.8.mlp.up_proj.weight                -> blk.8.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "model.layers.0.input_layernorm.weight            -> blk.0.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.0.mlp.down_proj.weight              -> blk.0.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.0.mlp.gate_proj.weight              -> blk.0.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.0.mlp.up_proj.weight                -> blk.0.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "model.layers.0.post_attention_layernorm.weight   -> blk.0.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.0.self_attn.k_proj.weight           -> blk.0.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.0.self_attn.o_proj.weight           -> blk.0.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.0.self_attn.q_proj.weight           -> blk.0.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.0.self_attn.v_proj.weight           -> blk.0.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.1.input_layernorm.weight            -> blk.1.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.1.mlp.down_proj.weight              -> blk.1.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.1.mlp.gate_proj.weight              -> blk.1.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.1.mlp.up_proj.weight                -> blk.1.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "model.layers.1.post_attention_layernorm.weight   -> blk.1.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.1.self_attn.k_proj.weight           -> blk.1.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.1.self_attn.o_proj.weight           -> blk.1.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.1.self_attn.q_proj.weight           -> blk.1.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.1.self_attn.v_proj.weight           -> blk.1.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.2.input_layernorm.weight            -> blk.2.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.2.mlp.down_proj.weight              -> blk.2.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.2.mlp.gate_proj.weight              -> blk.2.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.2.mlp.up_proj.weight                -> blk.2.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "model.layers.2.post_attention_layernorm.weight   -> blk.2.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.2.self_attn.k_proj.weight           -> blk.2.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.2.self_attn.o_proj.weight           -> blk.2.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.2.self_attn.q_proj.weight           -> blk.2.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.2.self_attn.v_proj.weight           -> blk.2.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.3.input_layernorm.weight            -> blk.3.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.3.mlp.down_proj.weight              -> blk.3.ffn_down.weight                    | BF16   | [4096, 14336]\n",
            "model.layers.3.mlp.gate_proj.weight              -> blk.3.ffn_gate.weight                    | BF16   | [14336, 4096]\n",
            "model.layers.3.mlp.up_proj.weight                -> blk.3.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "model.layers.3.post_attention_layernorm.weight   -> blk.3.ffn_norm.weight                    | BF16   | [4096]\n",
            "model.layers.3.self_attn.k_proj.weight           -> blk.3.attn_k.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.3.self_attn.o_proj.weight           -> blk.3.attn_output.weight                 | BF16   | [4096, 4096]\n",
            "model.layers.3.self_attn.q_proj.weight           -> blk.3.attn_q.weight                      | BF16   | [4096, 4096]\n",
            "model.layers.3.self_attn.v_proj.weight           -> blk.3.attn_v.weight                      | BF16   | [1024, 4096]\n",
            "model.layers.4.input_layernorm.weight            -> blk.4.attn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.4.mlp.up_proj.weight                -> blk.4.ffn_up.weight                      | BF16   | [14336, 4096]\n",
            "lm_head.weight                                   -> output.weight                            | BF16   | [32000, 4096]\n",
            "model.embed_tokens.weight                        -> token_embd.weight                        | BF16   | [32000, 4096]\n",
            "model.layers.28.post_attention_layernorm.weight  -> blk.28.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.28.self_attn.k_proj.weight          -> blk.28.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.28.self_attn.o_proj.weight          -> blk.28.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.28.self_attn.q_proj.weight          -> blk.28.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.28.self_attn.v_proj.weight          -> blk.28.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.29.input_layernorm.weight           -> blk.29.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.29.mlp.down_proj.weight             -> blk.29.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.29.mlp.gate_proj.weight             -> blk.29.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.29.mlp.up_proj.weight               -> blk.29.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.29.post_attention_layernorm.weight  -> blk.29.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.29.self_attn.k_proj.weight          -> blk.29.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.29.self_attn.o_proj.weight          -> blk.29.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.29.self_attn.q_proj.weight          -> blk.29.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.29.self_attn.v_proj.weight          -> blk.29.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.30.input_layernorm.weight           -> blk.30.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.30.mlp.down_proj.weight             -> blk.30.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.30.mlp.gate_proj.weight             -> blk.30.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.30.mlp.up_proj.weight               -> blk.30.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.30.post_attention_layernorm.weight  -> blk.30.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.30.self_attn.k_proj.weight          -> blk.30.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.30.self_attn.o_proj.weight          -> blk.30.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.30.self_attn.q_proj.weight          -> blk.30.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.30.self_attn.v_proj.weight          -> blk.30.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.31.input_layernorm.weight           -> blk.31.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.31.mlp.down_proj.weight             -> blk.31.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.31.mlp.gate_proj.weight             -> blk.31.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.31.mlp.up_proj.weight               -> blk.31.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.31.post_attention_layernorm.weight  -> blk.31.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.31.self_attn.k_proj.weight          -> blk.31.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.31.self_attn.o_proj.weight          -> blk.31.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.31.self_attn.q_proj.weight          -> blk.31.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.31.self_attn.v_proj.weight          -> blk.31.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.norm.weight                                -> output_norm.weight                       | BF16   | [4096]\n",
            "model.layers.24.mlp.down_proj.weight             -> blk.24.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.24.mlp.gate_proj.weight             -> blk.24.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.24.post_attention_layernorm.weight  -> blk.24.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.24.self_attn.k_proj.weight          -> blk.24.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.24.self_attn.o_proj.weight          -> blk.24.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.24.self_attn.q_proj.weight          -> blk.24.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.24.self_attn.v_proj.weight          -> blk.24.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.25.input_layernorm.weight           -> blk.25.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.25.mlp.down_proj.weight             -> blk.25.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.25.mlp.gate_proj.weight             -> blk.25.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.25.mlp.up_proj.weight               -> blk.25.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.25.post_attention_layernorm.weight  -> blk.25.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.25.self_attn.k_proj.weight          -> blk.25.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.25.self_attn.o_proj.weight          -> blk.25.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.25.self_attn.q_proj.weight          -> blk.25.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.25.self_attn.v_proj.weight          -> blk.25.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.26.input_layernorm.weight           -> blk.26.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.26.mlp.down_proj.weight             -> blk.26.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.26.mlp.gate_proj.weight             -> blk.26.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.26.mlp.up_proj.weight               -> blk.26.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.26.post_attention_layernorm.weight  -> blk.26.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.26.self_attn.k_proj.weight          -> blk.26.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.26.self_attn.o_proj.weight          -> blk.26.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.26.self_attn.q_proj.weight          -> blk.26.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.26.self_attn.v_proj.weight          -> blk.26.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.27.input_layernorm.weight           -> blk.27.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.27.mlp.down_proj.weight             -> blk.27.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.27.mlp.gate_proj.weight             -> blk.27.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.27.mlp.up_proj.weight               -> blk.27.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.27.post_attention_layernorm.weight  -> blk.27.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.27.self_attn.k_proj.weight          -> blk.27.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.27.self_attn.o_proj.weight          -> blk.27.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.27.self_attn.q_proj.weight          -> blk.27.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.27.self_attn.v_proj.weight          -> blk.27.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.28.input_layernorm.weight           -> blk.28.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.28.mlp.down_proj.weight             -> blk.28.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.28.mlp.gate_proj.weight             -> blk.28.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.28.mlp.up_proj.weight               -> blk.28.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.22.input_layernorm.weight           -> blk.22.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.22.mlp.down_proj.weight             -> blk.22.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.22.mlp.gate_proj.weight             -> blk.22.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.22.mlp.up_proj.weight               -> blk.22.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.22.post_attention_layernorm.weight  -> blk.22.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.23.input_layernorm.weight           -> blk.23.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.23.mlp.down_proj.weight             -> blk.23.ffn_down.weight                   | BF16   | [4096, 14336]\n",
            "model.layers.23.mlp.gate_proj.weight             -> blk.23.ffn_gate.weight                   | BF16   | [14336, 4096]\n",
            "model.layers.23.mlp.up_proj.weight               -> blk.23.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "model.layers.23.post_attention_layernorm.weight  -> blk.23.ffn_norm.weight                   | BF16   | [4096]\n",
            "model.layers.23.self_attn.k_proj.weight          -> blk.23.attn_k.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.23.self_attn.o_proj.weight          -> blk.23.attn_output.weight                | BF16   | [4096, 4096]\n",
            "model.layers.23.self_attn.q_proj.weight          -> blk.23.attn_q.weight                     | BF16   | [4096, 4096]\n",
            "model.layers.23.self_attn.v_proj.weight          -> blk.23.attn_v.weight                     | BF16   | [1024, 4096]\n",
            "model.layers.24.input_layernorm.weight           -> blk.24.attn_norm.weight                  | BF16   | [4096]\n",
            "model.layers.24.mlp.up_proj.weight               -> blk.24.ffn_up.weight                     | BF16   | [14336, 4096]\n",
            "Writing merge/ggml-model-f16.gguf, format 1\n",
            "Ignoring added_tokens.json since model matches vocab size without it.\n",
            "gguf: This GGUF file is for Little Endian only\n",
            "gguf: Setting special token type bos to 1\n",
            "gguf: Setting special token type eos to 2\n",
            "gguf: Setting special token type unk to 0\n",
            "[  1/291] Writing tensor blk.17.ffn_norm.weight                 | size   4096           | type F32  | T+   0\n",
            "[  2/291] Writing tensor blk.17.attn_k.weight                   | size   1024 x   4096  | type F16  | T+   0\n",
            "[  3/291] Writing tensor blk.17.attn_output.weight              | size   4096 x   4096  | type F16  | T+   1\n",
            "[  4/291] Writing tensor blk.17.attn_q.weight                   | size   4096 x   4096  | type F16  | T+   2\n",
            "[  5/291] Writing tensor blk.17.attn_v.weight                   | size   1024 x   4096  | type F16  | T+   2\n",
            "[  6/291] Writing tensor blk.18.attn_norm.weight                | size   4096           | type F32  | T+   3\n",
            "[  7/291] Writing tensor blk.18.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+   4\n",
            "[  8/291] Writing tensor blk.18.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+   5\n",
            "[  9/291] Writing tensor blk.18.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  10\n",
            "[ 10/291] Writing tensor blk.18.ffn_norm.weight                 | size   4096           | type F32  | T+  10\n",
            "[ 11/291] Writing tensor blk.18.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  10\n",
            "[ 12/291] Writing tensor blk.18.attn_output.weight              | size   4096 x   4096  | type F16  | T+  10\n",
            "[ 13/291] Writing tensor blk.18.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  10\n",
            "[ 14/291] Writing tensor blk.18.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  11\n",
            "[ 15/291] Writing tensor blk.19.attn_norm.weight                | size   4096           | type F32  | T+  11\n",
            "[ 16/291] Writing tensor blk.19.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  11\n",
            "[ 17/291] Writing tensor blk.19.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  13\n",
            "[ 18/291] Writing tensor blk.19.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  14\n",
            "[ 19/291] Writing tensor blk.19.ffn_norm.weight                 | size   4096           | type F32  | T+  15\n",
            "[ 20/291] Writing tensor blk.19.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  15\n",
            "[ 21/291] Writing tensor blk.19.attn_output.weight              | size   4096 x   4096  | type F16  | T+  15\n",
            "[ 22/291] Writing tensor blk.19.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  15\n",
            "[ 23/291] Writing tensor blk.19.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  15\n",
            "[ 24/291] Writing tensor blk.20.attn_norm.weight                | size   4096           | type F32  | T+  15\n",
            "[ 25/291] Writing tensor blk.20.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  15\n",
            "[ 26/291] Writing tensor blk.20.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  17\n",
            "[ 27/291] Writing tensor blk.20.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  18\n",
            "[ 28/291] Writing tensor blk.20.ffn_norm.weight                 | size   4096           | type F32  | T+  19\n",
            "[ 29/291] Writing tensor blk.20.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  19\n",
            "[ 30/291] Writing tensor blk.20.attn_output.weight              | size   4096 x   4096  | type F16  | T+  19\n",
            "[ 31/291] Writing tensor blk.20.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  20\n",
            "[ 32/291] Writing tensor blk.20.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  20\n",
            "[ 33/291] Writing tensor blk.21.attn_norm.weight                | size   4096           | type F32  | T+  20\n",
            "[ 34/291] Writing tensor blk.21.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  20\n",
            "[ 35/291] Writing tensor blk.21.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  22\n",
            "[ 36/291] Writing tensor blk.21.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  23\n",
            "[ 37/291] Writing tensor blk.21.ffn_norm.weight                 | size   4096           | type F32  | T+  25\n",
            "[ 38/291] Writing tensor blk.21.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  25\n",
            "[ 39/291] Writing tensor blk.21.attn_output.weight              | size   4096 x   4096  | type F16  | T+  25\n",
            "[ 40/291] Writing tensor blk.21.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  25\n",
            "[ 41/291] Writing tensor blk.21.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  25\n",
            "[ 42/291] Writing tensor blk.22.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  25\n",
            "[ 43/291] Writing tensor blk.22.attn_output.weight              | size   4096 x   4096  | type F16  | T+  25\n",
            "[ 44/291] Writing tensor blk.22.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  25\n",
            "[ 45/291] Writing tensor blk.22.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  25\n",
            "[ 46/291] Writing tensor blk.13.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  28\n",
            "[ 47/291] Writing tensor blk.13.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  28\n",
            "[ 48/291] Writing tensor blk.13.ffn_norm.weight                 | size   4096           | type F32  | T+  29\n",
            "[ 49/291] Writing tensor blk.13.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  29\n",
            "[ 50/291] Writing tensor blk.13.attn_output.weight              | size   4096 x   4096  | type F16  | T+  29\n",
            "[ 51/291] Writing tensor blk.13.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  29\n",
            "[ 52/291] Writing tensor blk.13.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  29\n",
            "[ 53/291] Writing tensor blk.14.attn_norm.weight                | size   4096           | type F32  | T+  29\n",
            "[ 54/291] Writing tensor blk.14.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  31\n",
            "[ 55/291] Writing tensor blk.14.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  32\n",
            "[ 56/291] Writing tensor blk.14.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  32\n",
            "[ 57/291] Writing tensor blk.14.ffn_norm.weight                 | size   4096           | type F32  | T+  32\n",
            "[ 58/291] Writing tensor blk.14.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  32\n",
            "[ 59/291] Writing tensor blk.14.attn_output.weight              | size   4096 x   4096  | type F16  | T+  32\n",
            "[ 60/291] Writing tensor blk.14.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  32\n",
            "[ 61/291] Writing tensor blk.14.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  33\n",
            "[ 62/291] Writing tensor blk.15.attn_norm.weight                | size   4096           | type F32  | T+  33\n",
            "[ 63/291] Writing tensor blk.15.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  36\n",
            "[ 64/291] Writing tensor blk.15.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  37\n",
            "[ 65/291] Writing tensor blk.15.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  37\n",
            "[ 66/291] Writing tensor blk.15.ffn_norm.weight                 | size   4096           | type F32  | T+  37\n",
            "[ 67/291] Writing tensor blk.15.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  37\n",
            "[ 68/291] Writing tensor blk.15.attn_output.weight              | size   4096 x   4096  | type F16  | T+  37\n",
            "[ 69/291] Writing tensor blk.15.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  37\n",
            "[ 70/291] Writing tensor blk.15.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  37\n",
            "[ 71/291] Writing tensor blk.16.attn_norm.weight                | size   4096           | type F32  | T+  38\n",
            "[ 72/291] Writing tensor blk.16.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  41\n",
            "[ 73/291] Writing tensor blk.16.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  41\n",
            "[ 74/291] Writing tensor blk.16.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  42\n",
            "[ 75/291] Writing tensor blk.16.ffn_norm.weight                 | size   4096           | type F32  | T+  43\n",
            "[ 76/291] Writing tensor blk.16.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  43\n",
            "[ 77/291] Writing tensor blk.16.attn_output.weight              | size   4096 x   4096  | type F16  | T+  43\n",
            "[ 78/291] Writing tensor blk.16.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  43\n",
            "[ 79/291] Writing tensor blk.16.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  47\n",
            "[ 80/291] Writing tensor blk.17.attn_norm.weight                | size   4096           | type F32  | T+  47\n",
            "[ 81/291] Writing tensor blk.17.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  47\n",
            "[ 82/291] Writing tensor blk.17.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  48\n",
            "[ 83/291] Writing tensor blk.17.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  48\n",
            "[ 84/291] Writing tensor blk.10.attn_norm.weight                | size   4096           | type F32  | T+  48\n",
            "[ 85/291] Writing tensor blk.10.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  48\n",
            "[ 86/291] Writing tensor blk.10.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  49\n",
            "[ 87/291] Writing tensor blk.10.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  51\n",
            "[ 88/291] Writing tensor blk.10.ffn_norm.weight                 | size   4096           | type F32  | T+  51\n",
            "[ 89/291] Writing tensor blk.10.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  51\n",
            "[ 90/291] Writing tensor blk.10.attn_output.weight              | size   4096 x   4096  | type F16  | T+  51\n",
            "[ 91/291] Writing tensor blk.10.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  51\n",
            "[ 92/291] Writing tensor blk.10.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  51\n",
            "[ 93/291] Writing tensor blk.11.attn_norm.weight                | size   4096           | type F32  | T+  51\n",
            "[ 94/291] Writing tensor blk.11.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  51\n",
            "[ 95/291] Writing tensor blk.11.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  54\n",
            "[ 96/291] Writing tensor blk.11.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  54\n",
            "[ 97/291] Writing tensor blk.11.ffn_norm.weight                 | size   4096           | type F32  | T+  55\n",
            "[ 98/291] Writing tensor blk.11.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  55\n",
            "[ 99/291] Writing tensor blk.11.attn_output.weight              | size   4096 x   4096  | type F16  | T+  55\n",
            "[100/291] Writing tensor blk.11.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  55\n",
            "[101/291] Writing tensor blk.11.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  55\n",
            "[102/291] Writing tensor blk.12.attn_norm.weight                | size   4096           | type F32  | T+  55\n",
            "[103/291] Writing tensor blk.12.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+  58\n",
            "[104/291] Writing tensor blk.12.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+  58\n",
            "[105/291] Writing tensor blk.12.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  59\n",
            "[106/291] Writing tensor blk.12.ffn_norm.weight                 | size   4096           | type F32  | T+  59\n",
            "[107/291] Writing tensor blk.12.attn_k.weight                   | size   1024 x   4096  | type F16  | T+  59\n",
            "[108/291] Writing tensor blk.12.attn_output.weight              | size   4096 x   4096  | type F16  | T+  59\n",
            "[109/291] Writing tensor blk.12.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  59\n",
            "[110/291] Writing tensor blk.12.attn_v.weight                   | size   1024 x   4096  | type F16  | T+  59\n",
            "[111/291] Writing tensor blk.13.attn_norm.weight                | size   4096           | type F32  | T+  59\n",
            "[112/291] Writing tensor blk.13.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+  62\n",
            "[113/291] Writing tensor blk.8.ffn_norm.weight                  | size   4096           | type F32  | T+  63\n",
            "[114/291] Writing tensor blk.8.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  63\n",
            "[115/291] Writing tensor blk.8.attn_output.weight               | size   4096 x   4096  | type F16  | T+  63\n",
            "[116/291] Writing tensor blk.8.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  63\n",
            "[117/291] Writing tensor blk.8.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  63\n",
            "[118/291] Writing tensor blk.9.attn_norm.weight                 | size   4096           | type F32  | T+  63\n",
            "[119/291] Writing tensor blk.9.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  63\n",
            "[120/291] Writing tensor blk.9.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  66\n",
            "[121/291] Writing tensor blk.9.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  68\n",
            "[122/291] Writing tensor blk.9.ffn_norm.weight                  | size   4096           | type F32  | T+  69\n",
            "[123/291] Writing tensor blk.9.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  69\n",
            "[124/291] Writing tensor blk.9.attn_output.weight               | size   4096 x   4096  | type F16  | T+  69\n",
            "[125/291] Writing tensor blk.9.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  69\n",
            "[126/291] Writing tensor blk.9.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  69\n",
            "[127/291] Writing tensor blk.4.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  69\n",
            "[128/291] Writing tensor blk.4.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  69\n",
            "[129/291] Writing tensor blk.4.ffn_norm.weight                  | size   4096           | type F32  | T+  70\n",
            "[130/291] Writing tensor blk.4.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  70\n",
            "[131/291] Writing tensor blk.4.attn_output.weight               | size   4096 x   4096  | type F16  | T+  71\n",
            "[132/291] Writing tensor blk.4.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  71\n",
            "[133/291] Writing tensor blk.4.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  71\n",
            "[134/291] Writing tensor blk.5.attn_norm.weight                 | size   4096           | type F32  | T+  71\n",
            "[135/291] Writing tensor blk.5.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  75\n",
            "[136/291] Writing tensor blk.5.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  75\n",
            "[137/291] Writing tensor blk.5.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  76\n",
            "[138/291] Writing tensor blk.5.ffn_norm.weight                  | size   4096           | type F32  | T+  81\n",
            "[139/291] Writing tensor blk.5.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  81\n",
            "[140/291] Writing tensor blk.5.attn_output.weight               | size   4096 x   4096  | type F16  | T+  81\n",
            "[141/291] Writing tensor blk.5.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  81\n",
            "[142/291] Writing tensor blk.5.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  87\n",
            "[143/291] Writing tensor blk.6.attn_norm.weight                 | size   4096           | type F32  | T+  87\n",
            "[144/291] Writing tensor blk.6.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  90\n",
            "[145/291] Writing tensor blk.6.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  90\n",
            "[146/291] Writing tensor blk.6.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  91\n",
            "[147/291] Writing tensor blk.6.ffn_norm.weight                  | size   4096           | type F32  | T+  91\n",
            "[148/291] Writing tensor blk.6.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  91\n",
            "[149/291] Writing tensor blk.6.attn_output.weight               | size   4096 x   4096  | type F16  | T+  91\n",
            "[150/291] Writing tensor blk.6.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  91\n",
            "[151/291] Writing tensor blk.6.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  91\n",
            "[152/291] Writing tensor blk.7.attn_norm.weight                 | size   4096           | type F32  | T+  91\n",
            "[153/291] Writing tensor blk.7.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+  95\n",
            "[154/291] Writing tensor blk.7.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+  95\n",
            "[155/291] Writing tensor blk.7.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+  96\n",
            "[156/291] Writing tensor blk.7.ffn_norm.weight                  | size   4096           | type F32  | T+  96\n",
            "[157/291] Writing tensor blk.7.attn_k.weight                    | size   1024 x   4096  | type F16  | T+  96\n",
            "[158/291] Writing tensor blk.7.attn_output.weight               | size   4096 x   4096  | type F16  | T+  96\n",
            "[159/291] Writing tensor blk.7.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  96\n",
            "[160/291] Writing tensor blk.7.attn_v.weight                    | size   1024 x   4096  | type F16  | T+  96\n",
            "[161/291] Writing tensor blk.8.attn_norm.weight                 | size   4096           | type F32  | T+  96\n",
            "[162/291] Writing tensor blk.8.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+ 102\n",
            "[163/291] Writing tensor blk.8.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+ 103\n",
            "[164/291] Writing tensor blk.8.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+ 104\n",
            "[165/291] Writing tensor blk.0.attn_norm.weight                 | size   4096           | type F32  | T+ 104\n",
            "[166/291] Writing tensor blk.0.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+ 104\n",
            "[167/291] Writing tensor blk.0.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+ 104\n",
            "[168/291] Writing tensor blk.0.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+ 105\n",
            "[169/291] Writing tensor blk.0.ffn_norm.weight                  | size   4096           | type F32  | T+ 105\n",
            "[170/291] Writing tensor blk.0.attn_k.weight                    | size   1024 x   4096  | type F16  | T+ 105\n",
            "[171/291] Writing tensor blk.0.attn_output.weight               | size   4096 x   4096  | type F16  | T+ 106\n",
            "[172/291] Writing tensor blk.0.attn_q.weight                    | size   4096 x   4096  | type F16  | T+ 106\n",
            "[173/291] Writing tensor blk.0.attn_v.weight                    | size   1024 x   4096  | type F16  | T+ 107\n",
            "[174/291] Writing tensor blk.1.attn_norm.weight                 | size   4096           | type F32  | T+ 107\n",
            "[175/291] Writing tensor blk.1.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+ 109\n",
            "[176/291] Writing tensor blk.1.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+ 110\n",
            "[177/291] Writing tensor blk.1.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+ 110\n",
            "[178/291] Writing tensor blk.1.ffn_norm.weight                  | size   4096           | type F32  | T+ 110\n",
            "[179/291] Writing tensor blk.1.attn_k.weight                    | size   1024 x   4096  | type F16  | T+ 110\n",
            "[180/291] Writing tensor blk.1.attn_output.weight               | size   4096 x   4096  | type F16  | T+ 110\n",
            "[181/291] Writing tensor blk.1.attn_q.weight                    | size   4096 x   4096  | type F16  | T+ 110\n",
            "[182/291] Writing tensor blk.1.attn_v.weight                    | size   1024 x   4096  | type F16  | T+ 110\n",
            "[183/291] Writing tensor blk.2.attn_norm.weight                 | size   4096           | type F32  | T+ 110\n",
            "[184/291] Writing tensor blk.2.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+ 114\n",
            "[185/291] Writing tensor blk.2.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+ 115\n",
            "[186/291] Writing tensor blk.2.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+ 115\n",
            "[187/291] Writing tensor blk.2.ffn_norm.weight                  | size   4096           | type F32  | T+ 115\n",
            "[188/291] Writing tensor blk.2.attn_k.weight                    | size   1024 x   4096  | type F16  | T+ 115\n",
            "[189/291] Writing tensor blk.2.attn_output.weight               | size   4096 x   4096  | type F16  | T+ 115\n",
            "[190/291] Writing tensor blk.2.attn_q.weight                    | size   4096 x   4096  | type F16  | T+ 115\n",
            "[191/291] Writing tensor blk.2.attn_v.weight                    | size   1024 x   4096  | type F16  | T+ 116\n",
            "[192/291] Writing tensor blk.3.attn_norm.weight                 | size   4096           | type F32  | T+ 116\n",
            "[193/291] Writing tensor blk.3.ffn_down.weight                  | size   4096 x  14336  | type F16  | T+ 119\n",
            "[194/291] Writing tensor blk.3.ffn_gate.weight                  | size  14336 x   4096  | type F16  | T+ 119\n",
            "[195/291] Writing tensor blk.3.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+ 120\n",
            "[196/291] Writing tensor blk.3.ffn_norm.weight                  | size   4096           | type F32  | T+ 120\n",
            "[197/291] Writing tensor blk.3.attn_k.weight                    | size   1024 x   4096  | type F16  | T+ 120\n",
            "[198/291] Writing tensor blk.3.attn_output.weight               | size   4096 x   4096  | type F16  | T+ 120\n",
            "[199/291] Writing tensor blk.3.attn_q.weight                    | size   4096 x   4096  | type F16  | T+ 120\n",
            "[200/291] Writing tensor blk.3.attn_v.weight                    | size   1024 x   4096  | type F16  | T+ 120\n",
            "[201/291] Writing tensor blk.4.attn_norm.weight                 | size   4096           | type F32  | T+ 121\n",
            "[202/291] Writing tensor blk.4.ffn_up.weight                    | size  14336 x   4096  | type F16  | T+ 123\n",
            "[203/291] Writing tensor output.weight                          | size  32000 x   4096  | type F16  | T+ 127\n",
            "[204/291] Writing tensor token_embd.weight                      | size  32000 x   4096  | type F16  | T+ 127\n",
            "[205/291] Writing tensor blk.28.ffn_norm.weight                 | size   4096           | type F32  | T+ 128\n",
            "[206/291] Writing tensor blk.28.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 128\n",
            "[207/291] Writing tensor blk.28.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 128\n",
            "[208/291] Writing tensor blk.28.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 128\n",
            "[209/291] Writing tensor blk.28.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 129\n",
            "[210/291] Writing tensor blk.29.attn_norm.weight                | size   4096           | type F32  | T+ 129\n",
            "[211/291] Writing tensor blk.29.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 131\n",
            "[212/291] Writing tensor blk.29.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 131\n",
            "[213/291] Writing tensor blk.29.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 132\n",
            "[214/291] Writing tensor blk.29.ffn_norm.weight                 | size   4096           | type F32  | T+ 132\n",
            "[215/291] Writing tensor blk.29.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 132\n",
            "[216/291] Writing tensor blk.29.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 132\n",
            "[217/291] Writing tensor blk.29.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 133\n",
            "[218/291] Writing tensor blk.29.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 133\n",
            "[219/291] Writing tensor blk.30.attn_norm.weight                | size   4096           | type F32  | T+ 133\n",
            "[220/291] Writing tensor blk.30.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 135\n",
            "[221/291] Writing tensor blk.30.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 136\n",
            "[222/291] Writing tensor blk.30.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 137\n",
            "[223/291] Writing tensor blk.30.ffn_norm.weight                 | size   4096           | type F32  | T+ 137\n",
            "[224/291] Writing tensor blk.30.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 137\n",
            "[225/291] Writing tensor blk.30.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 138\n",
            "[226/291] Writing tensor blk.30.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 138\n",
            "[227/291] Writing tensor blk.30.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 138\n",
            "[228/291] Writing tensor blk.31.attn_norm.weight                | size   4096           | type F32  | T+ 138\n",
            "[229/291] Writing tensor blk.31.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 140\n",
            "[230/291] Writing tensor blk.31.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 141\n",
            "[231/291] Writing tensor blk.31.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 141\n",
            "[232/291] Writing tensor blk.31.ffn_norm.weight                 | size   4096           | type F32  | T+ 142\n",
            "[233/291] Writing tensor blk.31.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 142\n",
            "[234/291] Writing tensor blk.31.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 142\n",
            "[235/291] Writing tensor blk.31.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 142\n",
            "[236/291] Writing tensor blk.31.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 142\n",
            "[237/291] Writing tensor output_norm.weight                     | size   4096           | type F32  | T+ 142\n",
            "[238/291] Writing tensor blk.24.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 144\n",
            "[239/291] Writing tensor blk.24.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 144\n",
            "[240/291] Writing tensor blk.24.ffn_norm.weight                 | size   4096           | type F32  | T+ 144\n",
            "[241/291] Writing tensor blk.24.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 144\n",
            "[242/291] Writing tensor blk.24.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 144\n",
            "[243/291] Writing tensor blk.24.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 145\n",
            "[244/291] Writing tensor blk.24.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 145\n",
            "[245/291] Writing tensor blk.25.attn_norm.weight                | size   4096           | type F32  | T+ 145\n",
            "[246/291] Writing tensor blk.25.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 152\n",
            "[247/291] Writing tensor blk.25.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 152\n",
            "[248/291] Writing tensor blk.25.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 152\n",
            "[249/291] Writing tensor blk.25.ffn_norm.weight                 | size   4096           | type F32  | T+ 154\n",
            "[250/291] Writing tensor blk.25.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 154\n",
            "[251/291] Writing tensor blk.25.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 155\n",
            "[252/291] Writing tensor blk.25.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 160\n",
            "[253/291] Writing tensor blk.25.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 166\n",
            "[254/291] Writing tensor blk.26.attn_norm.weight                | size   4096           | type F32  | T+ 166\n",
            "[255/291] Writing tensor blk.26.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 173\n",
            "[256/291] Writing tensor blk.26.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 173\n",
            "[257/291] Writing tensor blk.26.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 174\n",
            "[258/291] Writing tensor blk.26.ffn_norm.weight                 | size   4096           | type F32  | T+ 174\n",
            "[259/291] Writing tensor blk.26.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 174\n",
            "[260/291] Writing tensor blk.26.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 174\n",
            "[261/291] Writing tensor blk.26.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 175\n",
            "[262/291] Writing tensor blk.26.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 175\n",
            "[263/291] Writing tensor blk.27.attn_norm.weight                | size   4096           | type F32  | T+ 175\n",
            "[264/291] Writing tensor blk.27.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 179\n",
            "[265/291] Writing tensor blk.27.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 179\n",
            "[266/291] Writing tensor blk.27.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 179\n",
            "[267/291] Writing tensor blk.27.ffn_norm.weight                 | size   4096           | type F32  | T+ 180\n",
            "[268/291] Writing tensor blk.27.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 180\n",
            "[269/291] Writing tensor blk.27.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 180\n",
            "[270/291] Writing tensor blk.27.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 180\n",
            "[271/291] Writing tensor blk.27.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 180\n",
            "[272/291] Writing tensor blk.28.attn_norm.weight                | size   4096           | type F32  | T+ 180\n",
            "[273/291] Writing tensor blk.28.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 186\n",
            "[274/291] Writing tensor blk.28.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 186\n",
            "[275/291] Writing tensor blk.28.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 186\n",
            "[276/291] Writing tensor blk.22.attn_norm.weight                | size   4096           | type F32  | T+ 187\n",
            "[277/291] Writing tensor blk.22.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 187\n",
            "[278/291] Writing tensor blk.22.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 187\n",
            "[279/291] Writing tensor blk.22.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 188\n",
            "[280/291] Writing tensor blk.22.ffn_norm.weight                 | size   4096           | type F32  | T+ 188\n",
            "[281/291] Writing tensor blk.23.attn_norm.weight                | size   4096           | type F32  | T+ 188\n",
            "[282/291] Writing tensor blk.23.ffn_down.weight                 | size   4096 x  14336  | type F16  | T+ 191\n",
            "[283/291] Writing tensor blk.23.ffn_gate.weight                 | size  14336 x   4096  | type F16  | T+ 191\n",
            "[284/291] Writing tensor blk.23.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 192\n",
            "[285/291] Writing tensor blk.23.ffn_norm.weight                 | size   4096           | type F32  | T+ 192\n",
            "[286/291] Writing tensor blk.23.attn_k.weight                   | size   1024 x   4096  | type F16  | T+ 192\n",
            "[287/291] Writing tensor blk.23.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 192\n",
            "[288/291] Writing tensor blk.23.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 192\n",
            "[289/291] Writing tensor blk.23.attn_v.weight                   | size   1024 x   4096  | type F16  | T+ 193\n",
            "[290/291] Writing tensor blk.24.attn_norm.weight                | size   4096           | type F32  | T+ 193\n",
            "[291/291] Writing tensor blk.24.ffn_up.weight                   | size  14336 x   4096  | type F16  | T+ 194\n",
            "Wrote merge/ggml-model-f16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quantizing to q5_k_m GGUF with Llama.cpp\n",
        "! llama.cpp/quantize merge/ggml-model-f16.gguf merge/m_q5_k_m.gguf q5_k_m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upQDhBdDo5mT",
        "outputId": "7752ca4d-5d8c-490f-ca93-b7734cc699da"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main: build = 1963 (c9b316c7)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing 'merge/ggml-model-f16.gguf' to 'merge/m_q5_k_m.gguf' as Q5_K_M\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from merge/ggml-model-f16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = .\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "llama_model_quantize_internal: meta size = 734848 bytes\n",
            "[   1/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   2/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[   3/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[   4/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[   5/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[   6/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   7/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[   8/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[   9/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  10/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  11/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  12/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  13/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  14/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  15/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  16/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  17/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  18/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  19/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  20/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  21/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  22/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  23/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  24/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  25/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  26/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  27/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  28/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  29/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  30/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  31/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  32/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  33/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  34/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  35/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  36/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  37/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  38/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  39/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  40/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  41/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  42/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  43/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  44/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  45/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  46/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  47/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  48/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  49/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  50/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  51/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  52/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  53/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  54/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  55/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  56/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  57/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  58/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  59/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  60/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  61/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  62/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  63/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  64/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  65/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  66/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  67/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  68/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  69/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  70/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  71/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  72/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  73/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  74/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  75/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  76/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  77/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  78/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  79/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  80/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  81/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  82/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  83/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  84/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  85/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  86/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  87/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  88/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  89/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  90/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  91/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  92/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  93/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  94/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  95/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  96/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[  97/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  98/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  99/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 100/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 101/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 102/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 103/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 104/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 105/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 106/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 107/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 108/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 109/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 110/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 111/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 112/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 113/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 114/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 115/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 116/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 117/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 118/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 119/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 120/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 121/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 122/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 123/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 124/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 125/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 126/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 127/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 128/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 129/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 130/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 131/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 132/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 133/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 134/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 135/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 136/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 137/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 138/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 139/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 140/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 141/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 142/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 143/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 144/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 145/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 146/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 147/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 148/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 149/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 150/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 151/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 152/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 153/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 154/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 155/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 156/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 157/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 158/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 159/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 160/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 161/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 162/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 163/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 164/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 165/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 166/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 167/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 168/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 169/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 170/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 171/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 172/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 173/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 174/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 175/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 176/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 177/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 178/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 179/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 180/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 181/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 182/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 183/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 184/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 185/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 186/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 187/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 188/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 189/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 190/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 191/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 192/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 193/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 194/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 195/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 196/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 197/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 198/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 199/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 200/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 201/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 202/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 203/ 291]                        output.weight - [ 4096, 32000,     1,     1], type =    f16, quantizing to q6_K .. size =   250.00 MiB ->   102.54 MiB\n",
            "[ 204/ 291]                    token_embd.weight - [ 4096, 32000,     1,     1], type =    f16, quantizing to q5_K .. size =   250.00 MiB ->    85.94 MiB\n",
            "[ 205/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 206/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 207/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 208/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 209/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 210/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 211/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 212/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 213/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 214/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 215/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 216/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 217/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 218/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 219/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 220/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 221/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 222/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 223/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 224/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 225/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 226/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 227/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 228/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 229/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 230/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 231/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 232/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 233/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 234/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 235/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 236/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 237/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 238/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 239/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 240/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 241/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 242/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 243/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 244/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 245/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 247/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 248/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 249/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 250/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 251/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 252/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 253/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 254/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 256/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 257/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 258/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 259/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 260/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 261/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 262/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 263/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 265/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 266/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 267/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 268/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 269/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 270/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 271/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 272/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 274/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 275/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 276/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 277/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 278/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 279/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 280/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 281/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 282/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 283/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 284/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "[ 285/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 286/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 287/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 288/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 289/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, quantizing to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 290/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, quantizing to q5_K .. size =   112.00 MiB ->    38.50 MiB\n",
            "llama_model_quantize_internal: model size  = 13813.02 MB\n",
            "llama_model_quantize_internal: quant size  =  4892.99 MB\n",
            "\n",
            "main: quantize time = 918268.61 ms\n",
            "main:    total time = 918268.61 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -la merge |grep gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R_9gsbquUdT",
        "outputId": "39f8cde9-bb41-4504-86cb-c8221bcc1659"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 14484731456 Jan 24 13:22 ggml-model-f16.gguf\n",
            "-rw-r--r-- 1 root root  5131409024 Jan 24 13:42 m_q5_k_m.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/48774285/how-to-download-file-created-in-colaboratory-workspace\n",
        "from google.colab import files\n",
        "files.download('merge/m_q5_k_m.gguf')"
      ],
      "metadata": {
        "id": "SzT6CR96u-z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Upload model to Hugging Face { display-mode: \"form\" }\n",
        "# @markdown Enter your HF username and the name of Colab secret that stores your [Hugging Face access token](https://huggingface.co/settings/tokens).\n",
        "username = 'mlabonne' # @param {type:\"string\"}\n",
        "token = 'HF_TOKEN' # @param {type:\"string\"}\n",
        "license = \"apache-2.0\" # @param [\"apache-2.0\", \"cc-by-nc-4.0\", \"mit\", \"openrail\"] {allow-input: true}\n",
        "\n",
        "!pip install -qU huggingface_hub\n",
        "\n",
        "import yaml\n",
        "\n",
        "from huggingface_hub import ModelCard, ModelCardData, HfApi\n",
        "from google.colab import userdata\n",
        "from jinja2 import Template\n",
        "\n",
        "if branch == \"main\":\n",
        "    template_text = \"\"\"\n",
        "---\n",
        "license: {{ license }}\n",
        "base_model:\n",
        "{%- for model in models %}\n",
        "  - {{ model }}\n",
        "{%- endfor %}\n",
        "tags:\n",
        "- merge\n",
        "- mergekit\n",
        "- lazymergekit\n",
        "{%- for model in models %}\n",
        "- {{ model }}\n",
        "{%- endfor %}\n",
        "---\n",
        "\n",
        "# {{ model_name }}\n",
        "\n",
        "{{ model_name }} is a merge of the following models using [LazyMergekit](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing):\n",
        "\n",
        "{%- for model in models %}\n",
        "* [{{ model }}](https://huggingface.co/{{ model }})\n",
        "{%- endfor %}\n",
        "\n",
        "## üß© Configuration\n",
        "\n",
        "```yaml\n",
        "{{- yaml_config -}}\n",
        "```\n",
        "\n",
        "## üíª Usage\n",
        "\n",
        "```python\n",
        "!pip install -qU transformers accelerate\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model = \"{{ username }}/{{ model_name }}\"\n",
        "messages = [{\"role\": \"user\", \"content\": \"What is a large language model?\"}]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "outputs = pipeline(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "print(outputs[0][\"generated_text\"])\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "    # Create a Jinja template object\n",
        "    jinja_template = Template(template_text.strip())\n",
        "\n",
        "    # Get list of models from config\n",
        "    data = yaml.safe_load(yaml_config)\n",
        "    if \"models\" in data:\n",
        "        models = [data[\"models\"][i][\"model\"] for i in range(len(data[\"models\"])) if \"parameters\" in data[\"models\"][i]]\n",
        "    elif \"parameters\" in data:\n",
        "        models = [data[\"slices\"][0][\"sources\"][i][\"model\"] for i in range(len(data[\"slices\"][0][\"sources\"]))]\n",
        "    elif \"slices\" in data:\n",
        "        models = [data[\"slices\"][i][\"sources\"][0][\"model\"] for i in range(len(data[\"slices\"]))]\n",
        "    else:\n",
        "        raise Exception(\"No models or slices found in yaml config\")\n",
        "\n",
        "    # Fill the template\n",
        "    content = jinja_template.render(\n",
        "        model_name=MODEL_NAME,\n",
        "        models=models,\n",
        "        yaml_config=yaml_config,\n",
        "        username=username,\n",
        "    )\n",
        "\n",
        "elif branch == \"mixtral\":\n",
        "    template_text = \"\"\"\n",
        "---\n",
        "license: {{ license }}\n",
        "base_model:\n",
        "{%- for model in models %}\n",
        "  - {{ model }}\n",
        "{%- endfor %}\n",
        "tags:\n",
        "- moe\n",
        "- frankenmoe\n",
        "- merge\n",
        "- mergekit\n",
        "- lazymergekit\n",
        "{%- for model in models %}\n",
        "- {{ model }}\n",
        "{%- endfor %}\n",
        "---\n",
        "\n",
        "# {{ model_name }}\n",
        "\n",
        "{{ model_name }} is a Mixure of Experts (MoE) made with the following models using [LazyMergekit](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing):\n",
        "\n",
        "{%- for model in models %}\n",
        "* [{{ model }}](https://huggingface.co/{{ model }})\n",
        "{%- endfor %}\n",
        "\n",
        "## üß© Configuration\n",
        "\n",
        "```yaml\n",
        "{{- yaml_config -}}\n",
        "```\n",
        "\n",
        "## üíª Usage\n",
        "\n",
        "```python\n",
        "!pip install -qU transformers bitsandbytes accelerate\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model = \"{{ username }}/{{ model_name }}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    model_kwargs={\"torch_dtype\": torch.float16, \"load_in_4bit\": True},\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"Explain what a Mixture of Experts is in less than 100 words.\"}]\n",
        "prompt = pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "outputs = pipeline(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "print(outputs[0][\"generated_text\"])\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "    # Create a Jinja template object\n",
        "    jinja_template = Template(template_text.strip())\n",
        "\n",
        "    # Fill the template\n",
        "    data = yaml.safe_load(yaml_config)\n",
        "    models = [model['source_model'] for model in data['experts']]\n",
        "\n",
        "    content = jinja_template.render(\n",
        "        model_name=MODEL_NAME,\n",
        "        models=models,\n",
        "        yaml_config=yaml_config,\n",
        "        username=username,\n",
        "        license=license\n",
        "    )\n",
        "\n",
        "# Save the model card\n",
        "card = ModelCard(content)\n",
        "card.save('merge/README.md')\n",
        "\n",
        "# Defined in the secrets tab in Google Colab\n",
        "api = HfApi(token=userdata.get(token))\n",
        "\n",
        "# Upload merge folder\n",
        "api.create_repo(\n",
        "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
        "    repo_type=\"model\",\n",
        "    exist_ok=True,\n",
        ")\n",
        "api.upload_folder(\n",
        "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
        "    folder_path=\"merge\",\n",
        ")"
      ],
      "metadata": {
        "id": "ik0V0dF55gfU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}